{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed\n",
    "\n",
    "# General syntax to import specific functions in a library: \n",
    "##from (library) import (specific library function)\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "# General syntax to import a library but no functions: \n",
    "##import (library) as (give the library a nickname/alias)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "%matplotlib tk\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33614\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "# file path of csv file\n",
    "Location = r'/Users/33614/ExternalDrive/SUPAERO/PIR_2A/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/SYL21/D_Drive/SUPAERO/PIR_2A/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33614\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################################\n",
    "####  BANK OF PARTS OF DATA\n",
    "\n",
    "all_raw_data = df #Entire recording from all electrodes\n",
    "\n",
    "full_signal = df.iloc[:,1] #Entire recording from the first electrode\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "# Sample rate and desired cutoff frequencies (in Hz).\n",
    "fs = 25000.0\n",
    "lowcut = 100.0\n",
    "highcut = 2500.0\n",
    "\n",
    "\n",
    "y = butter_bandpass_filter(df.iloc[:,1], lowcut, highcut, fs, order=6)\n",
    "\n",
    "\n",
    "filtereddf = pd.DataFrame(y)\n",
    "filtereddf.index = df.index\n",
    "\n",
    "signal_filtered = filtereddf.iloc[:,0] #Entire recording filtered by bandpass, for one electrode\n",
    "\n",
    "\n",
    "fs = 25000\n",
    "\n",
    "xminnoise = int(np.round(11114*(fs/1000)))\n",
    "xmaxnoise = int(np.round(18511*(fs/1000)))\n",
    "\n",
    "noise_data = filtereddf.iloc[xminnoise:xmaxnoise,0]\n",
    "\n",
    "xminspike = int(np.round(130826*(fs/1000)))\n",
    "xmaxspike = int(np.round(131699*(fs/1000)))\n",
    "\n",
    "burst_data = filtereddf.iloc[xminspike:xmaxspike,0]\n",
    "\n",
    "begin_data = signal_filtered.iloc[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold\n",
    "\n",
    "def test_valid_window(window, test_level = 5):\n",
    "    \"\"\"\n",
    "    window : the window in the signal that has to be tested\n",
    "    \n",
    "    This funtion test the window to insure that it doesn't contain the signal of interest (spike)\n",
    "    \"\"\"\n",
    "    #non zero ?\n",
    "    second = np.percentile(window, 2)\n",
    "    thirtyth = np.percentile(window, 30)\n",
    "    #print(str(second) + \"\\t\" + str(thirtyth) + \"\\t\" + str(second/thirtyth))\n",
    "    if abs(second/thirtyth) < test_level : \n",
    "        return True\n",
    "    else : \n",
    "        return False\n",
    "    \n",
    "def init_noise_levels(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      estimator_type = 'RMS',\n",
    "                      percentile_value = 25):\n",
    "    \n",
    "    if estimator_type == 'RMS':\n",
    "        return init_noise_levels_RMS(signal, fs, \n",
    "                      noise_window_size = noise_window_size,\n",
    "                      required_valid_windows = required_valid_windows,\n",
    "                      old_noise_level_propagation = old_noise_level_propagation, \n",
    "                      test_level = test_level,\n",
    "                      percentile_value = percentile_value)\n",
    "        \n",
    "    if estimator_type == 'MAD':\n",
    "        return init_noise_levels_MAD(signal, fs, \n",
    "                      noise_window_size = noise_window_size,\n",
    "                      required_valid_windows = required_valid_windows,\n",
    "                      old_noise_level_propagation = old_noise_level_propagation, \n",
    "                      test_level = test_level,\n",
    "                      percentile_value = percentile_value)\n",
    "    \n",
    "    return None\n",
    "    \n",
    "    \n",
    "def init_noise_levels_RMS(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      percentile_value = 25):\n",
    "    \n",
    "    nb_valid_windows = 0\n",
    "    list_RMS = []\n",
    "    noise_levels = []\n",
    "    \n",
    "    noise_level = -1\n",
    "    \n",
    "     \n",
    "    #boucle en indice\n",
    "#    for window_index in range(0,len(signal)-(len(signal)%int(fs*noise_window_size)),int(fs*noise_window_size)):\n",
    "    for window_index in range(0,len(signal),int(fs*noise_window_size)):\n",
    "        test = test_valid_window(signal.iloc[window_index: window_index + int(fs*noise_window_size)], test_level)\n",
    "        if nb_valid_windows < required_valid_windows:\n",
    "            if test == True :\n",
    "                RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                list_RMS.append(RMS)\n",
    "                nb_valid_windows += 1\n",
    "            \n",
    "            if nb_valid_windows == required_valid_windows:\n",
    "                noise_level = np.percentile(list_RMS, percentile_value)\n",
    "                for elm in range(0, window_index, int(fs*noise_window_size)):\n",
    "                    noise_levels.append(noise_level)\n",
    "                \n",
    "        else :\n",
    "            \"\"\"if test == True:\n",
    "                if (window + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window:]), 25)\n",
    "                else :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window: window + int(fs*noise_window_size)]), 25)\n",
    "                noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*N25\n",
    "            noise_levels.append(noise_level)\"\"\"\n",
    "            if test == True:\n",
    "                if (window_index + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    RMS = np.sqrt(np.mean(signal.iloc[window_index:]**2))\n",
    "                else :\n",
    "                    RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                list_RMS.append(RMS)\n",
    "                NX = np.percentile(list_RMS, percentile_value)\n",
    "                new_noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*NX\n",
    "                noise_level = new_noise_level\n",
    "            noise_levels.append(noise_level)\n",
    "            \n",
    "    #cas ou il n'y a pas eut 100 fenetres de bruit valides rencontrees\n",
    "    if noise_level == -1:\n",
    "        \n",
    "        #cas ou aucune fenetre valide n'a ete rencontree\n",
    "        if noise_levels == []:\n",
    "            for elm in range(0, len(signal), int(fs*noise_window_size)):\n",
    "                noise_levels.append(0)\n",
    "            \n",
    "        else:\n",
    "            noise_level = np.percentile(list_RMS, percentile_value)\n",
    "            for elm in range(0, len(signal), int(fs*noise_window_size)):\n",
    "                noise_levels.append(noise_level)\n",
    "        \n",
    "    \n",
    "    noise_levels.append(noise_level)        \n",
    "    plt.figure()\n",
    "    plt.plot(list_RMS)\n",
    "    plt.xlabel('Time Windows')\n",
    "    plt.title('RMS values')\n",
    "    plt.grid(True)\n",
    "                \n",
    "    return noise_levels\n",
    "\n",
    "def init_noise_levels_MAD(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      percentile_value = 25):\n",
    "    \n",
    "    nb_valid_windows = 0\n",
    "    list_MAD = []\n",
    "    noise_levels = []\n",
    "     \n",
    "    #boucle en indice\n",
    "    for window_index in range(0,len(signal),int(fs*noise_window_size)):\n",
    "        test = test_valid_window(signal.iloc[window_index: window_index + int(fs*noise_window_size)], test_level)\n",
    "        if nb_valid_windows < required_valid_windows:\n",
    "            if test == True :\n",
    "                ###RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                MAD = scipy.stats.median_absolute_deviation(signal.iloc[window_index: window_index + int(fs*noise_window_size)])\n",
    "                list_MAD.append(MAD)\n",
    "                nb_valid_windows += 1\n",
    "            \n",
    "            if nb_valid_windows == required_valid_windows:\n",
    "                noise_level = np.percentile(list_MAD, percentile_value)\n",
    "                for elm in range(0, window_index, int(fs*noise_window_size)):\n",
    "                    noise_levels.append(noise_level)\n",
    "                \n",
    "        else :\n",
    "            \"\"\"if test == True:\n",
    "                if (window + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window:]), 25)\n",
    "                else :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window: window + int(fs*noise_window_size)]), 25)\n",
    "                noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*N25\n",
    "            noise_levels.append(noise_level)\"\"\"\n",
    "            if test == True:\n",
    "                if (window_index + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    ###RMS = np.sqrt(np.mean(signal.iloc[window_index:]**2))\n",
    "                    MAD = scipy.stats.median_absolute_deviation(signal.iloc[window_index:])\n",
    "                else :\n",
    "                    ###RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                    MAD = scipy.stats.median_absolute_deviation(signal.iloc[window_index: window_index + int(fs*noise_window_size)])\n",
    "                list_MAD.append(MAD)\n",
    "                NX = np.percentile(list_MAD, percentile_value)\n",
    "                new_noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*NX\n",
    "                noise_level = new_noise_level\n",
    "            noise_levels.append(noise_level)\n",
    "    \n",
    "    noise_levels.append(noise_level)        \n",
    "    plt.figure()\n",
    "    plt.plot(list_MAD)\n",
    "    plt.xlabel('Time Windows')\n",
    "    plt.title('MAD values')\n",
    "    plt.grid(True)\n",
    "                \n",
    "    return noise_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find spike\n",
    "\n",
    "def find_spike(signal, initial_index, noise_levels, fs, spike_centers, \n",
    "               window_size = 0.001, \n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = 4):\n",
    "    \n",
    "    offset_index = int(np.round(signal.index[0]*fs/1000))\n",
    "    \n",
    "    if initial_index < len(signal) + offset_index:\n",
    "        i = initial_index\n",
    "        for value in signal.iloc[initial_index-offset_index:]:\n",
    "            threshold = threshold_factor*noise_levels[int(np.round((i/fs)//noise_window_size))]\n",
    "            if value > threshold or value < -threshold:\n",
    "                while(True):\n",
    "                    if i > initial_index + window_size*fs:\n",
    "                        b_point = int(np.round(i - window_size*fs)) - offset_index\n",
    "                    else :\n",
    "                        b_point = initial_index - offset_index\n",
    "                    if i < len(signal)+offset_index - window_size*fs-1:\n",
    "                        e_point = int(np.round(i + window_size*fs)) - offset_index\n",
    "                    else :\n",
    "                        e_point = len(signal)\n",
    "\n",
    "                    highest_value = signal.iloc[b_point: e_point].max()\n",
    "                    lowest_value = signal.iloc[b_point: e_point].min()\n",
    "                    \n",
    "                    if abs(highest_value) > abs(lowest_value):\n",
    "                        extremum_value = highest_value\n",
    "                    else : extremum_value = lowest_value\n",
    "                    #print(\"highest value:\"+str(highest_value))\n",
    "                    \n",
    "                    if extremum_value == value : # && 50% amplitude\n",
    "                        #print(\"Found high spike\")\n",
    "                        #print(\"index:\"+str(i))\n",
    "                        spike_centers.append(i)\n",
    "                        return (e_point+offset_index)\n",
    "                    \n",
    "                    else:\n",
    "                        #i = signal.index.get_loc(highest)\n",
    "                        #print(\"b_point high: \" + str(b_point))\n",
    "                        #print(\"e_point high: \" + str(e_point))\n",
    "                        if abs(highest_value) > abs(lowest_value):\n",
    "                            i = int(np.round(signal.iloc[b_point: e_point].idxmax()*fs/1000))\n",
    "                        else : \n",
    "                            #print(signal.iloc[b_point:e_point])\n",
    "                            i = int(np.round(signal.iloc[b_point: e_point].idxmin()*fs/1000))\n",
    "                        #print(\"i high: \"+str(i))\n",
    "                        #print(\"value: \"+str(signal.iloc[i]))\n",
    "                        value = signal.iloc[i-offset_index]\n",
    "                        \n",
    "                break                  \n",
    "            i += 1\n",
    "    return -2\n",
    "            \n",
    "def find_spikes(signal, noise_levels, fs, \n",
    "               window_size = 0.001, \n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = 4):\n",
    "    \n",
    "    initial = int(np.round(signal.index[0]*fs/1000))\n",
    "    spike_centers = []\n",
    "    \n",
    "    while initial != -2:\n",
    "        initial = find_spike(signal, initial, noise_levels, fs, spike_centers,\n",
    "                             window_size = window_size, \n",
    "                             noise_window_size = noise_window_size,\n",
    "                             threshold_factor = threshold_factor)\n",
    "    \n",
    "    return spike_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record spike\n",
    "\n",
    "def record_spikes(signal, fs, spike_centers,\n",
    "                  t_before = 0.001,\n",
    "                  t_after = 0.002):\n",
    "    \n",
    "    data = np.array([[float(x) for x in range(int(np.round(fs*(t_before+t_after)))+1)]])\n",
    "    \n",
    "    initial_index = int(np.round(signal.index[0]*fs/1000))\n",
    "    print('initial index:'+str(initial_index))\n",
    "    \n",
    "    for center in spike_centers:\n",
    "        if center < int(np.round(fs*t_before)) + initial_index:\n",
    "            spike = [0 for i in range(0, int(np.round(fs*t_before-(center-initial_index))))]\n",
    "            #print('spike before concat:'+ str(len(spike)))\n",
    "            #spike = np.concatenate(spike, signal.iloc[:center + int(np.round(fs*t_after))].values())\n",
    "            spike = np.concatenate((spike, signal.values[:center + int(np.round(fs*t_after)) - initial_index]))\n",
    "            #print('spike after concat:'+str(len(spike)))\n",
    "            data = np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "        elif center > int(np.round(len(signal)-fs*t_after)) + initial_index:\n",
    "            #spike = signal.iloc[int(np.round(center-fs*t_before)):].values()\n",
    "            spike = signal.values[int(np.round(center-fs*t_before))-initial_index:]\n",
    "            #print('spike before concat:'+str(len(spike)))\n",
    "            spike = np.concatenate((spike,[0 for i in range(0, int(np.round(fs*t_after-(len(signal)+initial_index-center))))]))\n",
    "            #print('spike after concat:'+str(len(spike)))\n",
    "            data = np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "        else :\n",
    "            #spike = signal.iloc[int(np.round(center - fs*t_before)): int(np.round(center + fs*t_after))+1].values()\n",
    "            spike = signal.values[int(np.round(center - fs*t_before))-initial_index: int(np.round(center + fs*t_after))+1-initial_index]\n",
    "            data = np.insert(data, len(data), spike, axis=0)\n",
    "\n",
    "    print(np.shape(data))\n",
    "    data = data.transpose()\n",
    "    #print(data)\n",
    "    spike_data = pd.DataFrame(data)\n",
    "    \n",
    "    return spike_data\n",
    "\n",
    "\n",
    "def record_spikes_oneline(signal, fs, spike_centers,\n",
    "                  t_before = 0.001,\n",
    "                  t_after = 0.002):\n",
    "    \n",
    "    data = np.array(['NaN' for x in range(len(signal))])\n",
    "    data = data.astype(float)\n",
    "    times = np.array(['NaN' for x in range(len(signal))])\n",
    "    times = times.astype(pd.Timestamp)\n",
    "    \n",
    "    for center in spike_centers:\n",
    "        if center < int(np.round(fs*t_before)):\n",
    "            data[:center + int(np.round(fs*t_after))] = signal.values[:center + int(np.round(fs*t_after))]\n",
    "            times[:center + int(np.round(fs*t_after))] = signal.index[:center + int(np.round(fs*t_after))]\n",
    "            \n",
    "        elif center > int(np.round(len(signal)-fs*t_after)):\n",
    "            data[int(np.round(center-fs*t_before)):] = signal.values[int(np.round(center-fs*t_before)):]\n",
    "            times[int(np.round(center-fs*t_before)):] = signal.index[int(np.round(center-fs*t_before)):]\n",
    "            \n",
    "        else :\n",
    "            data[int(np.round(center - fs*t_before)): int(np.round(center + fs*t_after))+1] = signal.values[int(np.round(center - fs*t_before)): int(np.round(center + fs*t_after))+1]\n",
    "            times[int(np.round(center - fs*t_before)): int(np.round(center + fs*t_after))+1] = signal.index[int(np.round(center - fs*t_before)): int(np.round(center + fs*t_after))+1]\n",
    "\n",
    "    spike_data_oneline = pd.DataFrame(data, index = times.astype(float))\n",
    "    \n",
    "    return spike_data_oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 25000\n",
    "\n",
    "noise_levels = init_noise_levels(signal_filtered, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = noise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_centers = find_spikes(signal, noise_levels, fs, \n",
    "                           window_size = 0.001, \n",
    "                           noise_window_size = 0.01,\n",
    "                           threshold_factor = 4)\n",
    "\n",
    "#spike_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial index:277850\n",
      "(17, 51)\n"
     ]
    }
   ],
   "source": [
    "spike_data = record_spikes(signal, fs, spike_centers, \n",
    "                  t_before = 0.001, \n",
    "                  t_after = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = np.array(spike_data.iloc[:,1:].values).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 for i in range(len(pca_data))]\n",
    "i=0\n",
    "for data in pca_data:\n",
    "    if data[25]>0:\n",
    "        y[i]=1\n",
    "    i+=1\n",
    "    \n",
    "fig = plt.figure(4, figsize=(4, 3))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "plt.cla()\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(pca_data)\n",
    "X = pca.transform(pca_data)\n",
    "\n",
    "# Reorder the labels to have colors matching the cluster results\n",
    "y = np.choose(y, [1, 0]).astype(np.float)\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, cmap=plt.cm.nipy_spectral,\n",
    "           edgecolor='k')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
