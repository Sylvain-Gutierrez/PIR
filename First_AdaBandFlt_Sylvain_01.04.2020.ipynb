{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33614\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33614\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "# file path of csv file\n",
    "Location = r'/Users/33614/ExternalDrive/SUPAERO/PIR_2A/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/SYL21/D_Drive/SUPAERO/PIR_2A/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold\n",
    "\n",
    "def test_valid_window(window, test_level = 5):\n",
    "    \"\"\"\n",
    "    window : the window in the signal that has to be tested\n",
    "    \n",
    "    This funtion test the window to insure that it doesn't contain the signal of interest (spike)\n",
    "    \"\"\"\n",
    "    #non zero ?\n",
    "    second = np.percentile(window, 2)\n",
    "    thirtyth = np.percentile(window, 30)\n",
    "    #print(str(second) + \"\\t\" + str(thirtyth) + \"\\t\" + str(second/thirtyth))\n",
    "    if abs(second/thirtyth) < test_level : \n",
    "        return True\n",
    "    else : \n",
    "        return False\n",
    "    \n",
    "\n",
    "def init_noise_levels(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5):\n",
    "    \n",
    "    nb_valid_windows = 0\n",
    "    list_RMS = []\n",
    "    noise_levels = []\n",
    "     \n",
    "    #boucle en indice\n",
    "    for window_index in range(0,len(signal)-(len(signal)%int(fs*noise_window_size)),int(fs*noise_window_size)):\n",
    "        test = test_valid_window(signal.iloc[window_index: window_index + int(fs*noise_window_size)], test_level)\n",
    "        if nb_valid_windows < required_valid_windows:\n",
    "            if test == True :\n",
    "                RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                list_RMS.append(RMS)\n",
    "                nb_valid_windows += 1\n",
    "            \n",
    "            if nb_valid_windows == required_valid_windows:\n",
    "                noise_level = np.percentile(list_RMS, 25)\n",
    "                for elm in range(0, window_index, int(fs*noise_window_size)):\n",
    "                    noise_levels.append(noise_level)\n",
    "                \n",
    "        else :\n",
    "            \"\"\"if test == True:\n",
    "                if (window + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window:]), 25)\n",
    "                else :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window: window + int(fs*noise_window_size)]), 25)\n",
    "                noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*N25\n",
    "            noise_levels.append(noise_level)\"\"\"\n",
    "            if test == True:\n",
    "                if (window_index + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    RMS = np.sqrt(np.mean(signal.iloc[window_index:]**2))\n",
    "                else :\n",
    "                    RMS = np.sqrt(np.mean(signal.iloc[window_index: window_index + int(fs*noise_window_size)]**2))\n",
    "                list_RMS.append(RMS)\n",
    "                N25 = np.percentile(list_RMS, 25)\n",
    "                new_noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*N25\n",
    "                noise_level = new_noise_level\n",
    "            noise_levels.append(noise_level)\n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(list_RMS)\n",
    "    plt.xlabel('Time')\n",
    "    plt.grid()\n",
    "                \n",
    "    return noise_levels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find spike\n",
    "\n",
    "def find_spike(signal, initial_index, noise_levels, fs, spike_centers, \n",
    "               window_size = 0.001, \n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = 4):\n",
    "    if initial_index < len(signal):\n",
    "        i = initial_index\n",
    "        for value in signal.iloc[initial_index:]:\n",
    "            #print(int((i/fs)//noise_window_size))\n",
    "            if value > threshold_factor*noise_levels[int((i/fs)//noise_window_size)]:\n",
    "                while(True):\n",
    "                    if i > initial_index + window_size*fs:\n",
    "                        b_point = int(i - window_size*fs)\n",
    "                    else :\n",
    "                        b_point = initial_index\n",
    "                    if i < len(signal)-window_size*fs-1:\n",
    "                        e_point = int(i + window_size*fs)\n",
    "                    else :\n",
    "                        e_point = len(signal)-1\n",
    "\n",
    "                    highest_value = signal.iloc[b_point: e_point].max()\n",
    "\n",
    "                    if highest_value == value : # && 50% amplitude\n",
    "                        spike_centers.append(i)\n",
    "                        return e_point\n",
    "                    \n",
    "                    else:\n",
    "                        #i = signal.index.get_loc(highest)\n",
    "                        i = int(signal.iloc[b_point: e_point].idxmax()*fs/1000)#index(highest_value)#+b_point\n",
    "                        value = signal.iloc[i]\n",
    "                        \n",
    "                break\n",
    "                    \n",
    "            if value < -threshold_factor*noise_levels[int((i/fs)//noise_window_size)]:\n",
    "                while(True):\n",
    "                    if i > initial_index + window_size*fs:\n",
    "                        b_point = int(i - window_size*fs)\n",
    "                    else :\n",
    "                        b_point = initial_index\n",
    "                    if i < len(signal)-window_size*fs-1:\n",
    "                        e_point = int(i + window_size*fs)\n",
    "                    else :\n",
    "                        e_point = len(signal)-1\n",
    "\n",
    "                    lowest_value = min(signal.iloc[b_point: e_point])\n",
    "\n",
    "                    if lowest_value == value : # && 50% amplitude\n",
    "                        spike_centers.append(i)                        \n",
    "                        return e_point\n",
    "                    \n",
    "                    else:\n",
    "                        #i = signal.index.get_loc(lowest)\n",
    "                        i = int(signal.iloc[b_point: e_point].idxmin()*fs/1000)#Index.get_loc(lowest_value)#+b_point\n",
    "                        value = signal.iloc[i]\n",
    "                        \n",
    "                break\n",
    "                  \n",
    "            i += 1\n",
    "    return -2\n",
    "            \n",
    "def find_spikes(signal, noise_levels, fs, \n",
    "               window_size = 0.001, \n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = 4):\n",
    "    \n",
    "    initial = 0\n",
    "    spike_centers = []\n",
    "    \n",
    "    while initial != -2:\n",
    "        initial = find_spike(signal, initial, noise_levels, fs, spike_centers,\n",
    "                             window_size = window_size, \n",
    "                             noise_window_size = noise_window_size,\n",
    "                             threshold_factor = threshold_factor)\n",
    "    \n",
    "    return spike_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record spike\n",
    "\n",
    "def record_spikes(signal, fs, spike_centers, \n",
    "                  t_before = 0.001, \n",
    "                  t_after = 0.002):\n",
    "    data = np.array([x for x in range(fs*(t_before+t_after)+1)])\n",
    "    \n",
    "    for center in spike_centers:\n",
    "        if center < fs*t_before:\n",
    "            spike = [0 for i in range(0, fs*t_before-center)]\n",
    "            spike = np.concatenate(spike, signal[:center + fs*t_after])\n",
    "            np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "        elif center > len(signal)-fs*t_after:\n",
    "            spike = signal[center-fs*t_before:]\n",
    "            spike = np.concatenate(spike,[0 for i in range(0, fs*t_after-(len(signal)-center))])\n",
    "            np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "        else :\n",
    "            spike = signal[center - fs*t_before: center + fs*t_after]\n",
    "            np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "    spike_data = pd.DataFrame(data[:,1:], index = data[:,0], columns=spike_centers)\n",
    "    \n",
    "    return spike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "%t           \n",
       "0.00        -1.02\n",
       "0.04        -3.30\n",
       "0.08        -3.86\n",
       "0.12        -3.41\n",
       "0.16        -4.20\n",
       "0.20        -1.82\n",
       "0.24        -1.48\n",
       "0.28        -2.39\n",
       "0.32        -2.73\n",
       "0.36        -3.64\n",
       "0.40        -2.73\n",
       "0.44         0.23\n",
       "0.48         0.80\n",
       "0.52         0.91\n",
       "0.56        -1.82\n",
       "0.60        -3.07\n",
       "0.64        -2.39\n",
       "0.68        -4.43\n",
       "0.72        -4.32\n",
       "0.76        -2.50\n",
       "0.80        -0.23\n",
       "0.84         1.36\n",
       "0.88         0.80\n",
       "0.92        -1.59\n",
       "0.96        -2.50\n",
       "1.00        -3.30\n",
       "1.04        -2.50\n",
       "1.08        -1.02\n",
       "1.12        -0.91\n",
       "1.16        -2.73\n",
       "             ... \n",
       "301798.80    0.80\n",
       "301798.84    1.48\n",
       "301798.88   -1.48\n",
       "301798.92   -1.70\n",
       "301798.96   -2.50\n",
       "301799.00   -1.59\n",
       "301799.04   -0.45\n",
       "301799.08   -1.48\n",
       "301799.12   -1.70\n",
       "301799.16   -0.91\n",
       "301799.20   -2.16\n",
       "301799.24   -1.82\n",
       "301799.28   -1.70\n",
       "301799.32   -2.50\n",
       "301799.36   -4.20\n",
       "301799.40   -6.14\n",
       "301799.44   -5.00\n",
       "301799.48   -1.02\n",
       "301799.52    1.14\n",
       "301799.56    2.84\n",
       "301799.60    4.66\n",
       "301799.64    5.57\n",
       "301799.68    3.41\n",
       "301799.72    2.05\n",
       "301799.76    1.82\n",
       "301799.80    0.68\n",
       "301799.84   -1.14\n",
       "301799.88   -3.41\n",
       "301799.92   -6.36\n",
       "301799.96   -6.93\n",
       "Name: El 31       , Length: 7545000, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = df.iloc[:,1]\n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33614\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# test of the functions\n",
    "\n",
    "signal = df.iloc[:,1]\n",
    "fs = 25000\n",
    "\n",
    "noise_levels = init_noise_levels(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(noise_levels)\n",
    "plt.xlabel('Time')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "18615\n",
      "hello\n",
      "18710\n",
      "hello\n",
      "18740\n",
      "hello\n",
      "18780\n",
      "hello\n",
      "18819\n",
      "hello\n",
      "18854\n",
      "hello\n",
      "18908\n",
      "hello\n",
      "hello\n",
      "coucou\n",
      "18997\n",
      "hello\n",
      "19026\n",
      "hello\n",
      "19054\n",
      "hello\n",
      "hello\n",
      "19115\n",
      "hello\n",
      "19169\n",
      "hello\n",
      "19203\n",
      "hello\n",
      "19256\n",
      "hello\n",
      "19292\n"
     ]
    }
   ],
   "source": [
    "spike_centers = []\n",
    "\n",
    "find_spike(signal, 0, noise_levels, fs, spike_centers, \n",
    "               window_size = 0.001, \n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = 4)\n",
    "\n",
    "spike_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data = record_spikes(signal, fs, spike_centers, \n",
    "                  t_before = 0.001, \n",
    "                  t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0,3,4,2,4,5,3]\n",
    "np.percentile(a[1: 4], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (100,20))\n",
    "plt.plot(spike_data.index, spike_data.iloc[:,1])\n",
    "plt.xlabel('Time')\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
