{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33614\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "# file path of csv file\n",
    "Location = r'/Users/33614/ExternalDrive/SUPAERO/PIR_2A/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/SYL21/D_Drive/SUPAERO/PIR_2A/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold\n",
    "\n",
    "def test_valid_window(window):\n",
    "    \"\"\"\n",
    "    window : the window in the signal that has to be tested\n",
    "    \n",
    "    This funtion test the window to insure that it doesn't contain the signal of interest (spike)\n",
    "    \"\"\"\n",
    "    #non zero ?\n",
    "    if np.percentile(window, 2)/np.percentile(window, 30) < 5 : return True\n",
    "    else : return False\n",
    "    \n",
    "\n",
    "def init_noise_levels(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8):\n",
    "    valid_windows = 0\n",
    "    initial_thresholds = []\n",
    "    noise_levels = []\n",
    "     \n",
    "    for window in range(0,len(signal)-(len(signal)%int(fs*noise_window_size)),int(fs*noise_window_size)):\n",
    "        test = test_valid_window(signal.iloc[window: window + int(fs*noise_window_size)])\n",
    "        if valid_windows < required_valid_windows:\n",
    "            if test == True :\n",
    "                threshold = np.sqrt(np.mean(signal.iloc[window: window + int(fs*noise_window_size)]**2))\n",
    "                initial_thresholds.append(threshold)\n",
    "                valid_windows += 1\n",
    "            \n",
    "            if valid_windows == required_valid_windows:\n",
    "                noise_level = np.percentile(initial_thresholds, 25)\n",
    "                for elm in range(0, window):\n",
    "                    noise_levels.append(noise_level)\n",
    "                \n",
    "        else :\n",
    "            \"\"\"if test == True:\n",
    "                if (window + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window:]), 25)\n",
    "                else :\n",
    "                    N25 = np.percentile(abs(signal.iloc[window: window + int(fs*noise_window_size)]), 25)\n",
    "                noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*N25\n",
    "            noise_levels.append(noise_level)\"\"\"\n",
    "            if test == True:\n",
    "                if (window + int(fs*noise_window_size)) > (len(signal)-1) :\n",
    "                    threshold = np.sqrt(np.mean(signal.iloc[window:]**2))\n",
    "                else :\n",
    "                    threshold = np.sqrt(np.mean(signal.iloc[window:window + int(fs*noise_window_size)]**2))\n",
    "                initial_thresholds.append(threshold)\n",
    "                N25 = np.percentile(initial_thresholds, 25)\n",
    "                noise_level = old_noise_level_propagation*noise_level + (1-old_noise_level_propagation)*N25\n",
    "            noise_levels.append(noise_level)\n",
    "                \n",
    "    return noise_levels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find spike\n",
    "\n",
    "def find_spike(signal, initial, noise_levels, fs, spike_centers, \n",
    "               window_size = 0.001, \n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = 4):\n",
    "    if initial < len(signal):\n",
    "        i = initial\n",
    "        for value in signal[initial:]:\n",
    "            print(int((i/fs)//noise_window_size))\n",
    "            if value > threshold_factor*noise_levels[int((i/fs)//noise_window_size)]:\n",
    "                while(True):\n",
    "                    if i > initial + window_size*fs:\n",
    "                        b_point = i - window_size*fs\n",
    "                    else :\n",
    "                        b_point = initial\n",
    "                    if i < len(signal)-window_size*fs-1:\n",
    "                        e_point = i + window_size*fs\n",
    "                    else :\n",
    "                        e_point = len(signal)-1\n",
    "\n",
    "                    highest_value = max(signal[b_point, e_point])\n",
    "\n",
    "                    if highest == value : # && 50% amplitude\n",
    "                        spike_centers.append(i)\n",
    "                        break\n",
    "                    \n",
    "                    else:\n",
    "                        #i = signal.index.get_loc(highest)\n",
    "                        i = signal[b_point, e_point].index(max(signal[b_point, e_point]))+b_point\n",
    "                        value = signal[i]\n",
    "                        \n",
    "                break\n",
    "                find_spike(signal, e_point+1, noise_levels, fs, spike_centers)\n",
    "                    \n",
    "            if value < -threshold_factor*noise_levels[(i/noise_window_size)//fs]:\n",
    "                while(True):\n",
    "                    if i > initial + window_size*fs:\n",
    "                        b_point = i - window_size*fs\n",
    "                    else :\n",
    "                        b_point = initial\n",
    "                    if i < len(signal)-window_size*fs-1:\n",
    "                        e_point = i + window_size*fs\n",
    "                    else :\n",
    "                        e_point = len(signal)-1\n",
    "\n",
    "                    lowest_value = min(signal[b_point, e_point])\n",
    "\n",
    "                    if lowest == value : # && 50% amplitude\n",
    "                        spike_centers.append(i)\n",
    "                        break\n",
    "                    \n",
    "                    else:\n",
    "                        #i = signal.index.get_loc(lowest)\n",
    "                        i = signal[b_point, e_point].index(min(signal[b_point, e_point]))+b_point\n",
    "                        value = signal[i]\n",
    "                        \n",
    "                break\n",
    "                find_spike(signal, e_point+1, noise_levels, fs, spike_centers)\n",
    "                  \n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record spike\n",
    "\n",
    "def record_spikes(signal, fs, spike_centers, \n",
    "                  t_before = 0.001, \n",
    "                  t_after = 0.002):\n",
    "    data = np.array([x for x in range(fs*(t_before+t_after)+1)])\n",
    "    \n",
    "    for center in spike_centers:\n",
    "        if center < fs*t_before:\n",
    "            spike = [0 for i in range(0, fs*t_before-center)]\n",
    "            spike = np.concatenate(spike, signal[:center + fs*t_after])\n",
    "            np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "        elif center > len(signal)-fs*t_after:\n",
    "            spike = signal[center-fs*t_before:]\n",
    "            spike = np.concatenate(spike,[0 for i in range(0, fs*t_after-(len(signal)-center))])\n",
    "            np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "        else :\n",
    "            spike = signal[center - fs*t_before: center + fs*t_after]\n",
    "            np.insert(data, len(data), spike, axis=0)\n",
    "            \n",
    "    spike_data = pd.DataFrame(data[:,1:], index = data[:,0], columns=spike_centers)\n",
    "    \n",
    "    return spike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "%t           \n",
       "0.00        -1.02\n",
       "0.04        -3.30\n",
       "0.08        -3.86\n",
       "0.12        -3.41\n",
       "0.16        -4.20\n",
       "0.20        -1.82\n",
       "0.24        -1.48\n",
       "0.28        -2.39\n",
       "0.32        -2.73\n",
       "0.36        -3.64\n",
       "0.40        -2.73\n",
       "0.44         0.23\n",
       "0.48         0.80\n",
       "0.52         0.91\n",
       "0.56        -1.82\n",
       "0.60        -3.07\n",
       "0.64        -2.39\n",
       "0.68        -4.43\n",
       "0.72        -4.32\n",
       "0.76        -2.50\n",
       "0.80        -0.23\n",
       "0.84         1.36\n",
       "0.88         0.80\n",
       "0.92        -1.59\n",
       "0.96        -2.50\n",
       "1.00        -3.30\n",
       "1.04        -2.50\n",
       "1.08        -1.02\n",
       "1.12        -0.91\n",
       "1.16        -2.73\n",
       "             ... \n",
       "301798.80    0.80\n",
       "301798.84    1.48\n",
       "301798.88   -1.48\n",
       "301798.92   -1.70\n",
       "301798.96   -2.50\n",
       "301799.00   -1.59\n",
       "301799.04   -0.45\n",
       "301799.08   -1.48\n",
       "301799.12   -1.70\n",
       "301799.16   -0.91\n",
       "301799.20   -2.16\n",
       "301799.24   -1.82\n",
       "301799.28   -1.70\n",
       "301799.32   -2.50\n",
       "301799.36   -4.20\n",
       "301799.40   -6.14\n",
       "301799.44   -5.00\n",
       "301799.48   -1.02\n",
       "301799.52    1.14\n",
       "301799.56    2.84\n",
       "301799.60    4.66\n",
       "301799.64    5.57\n",
       "301799.68    3.41\n",
       "301799.72    2.05\n",
       "301799.76    1.82\n",
       "301799.80    0.68\n",
       "301799.84   -1.14\n",
       "301799.88   -3.41\n",
       "301799.92   -6.36\n",
       "301799.96   -6.93\n",
       "Name: El 31       , Length: 7545000, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = df.iloc[:,1]\n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33614\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# test of the functions\n",
    "\n",
    "signal = df.iloc[:,1]\n",
    "fs = 25000\n",
    "\n",
    "noise_levels = init_noise_levels(signal, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (100,20))\n",
    "plt.plot(noise_levels)\n",
    "plt.xlabel('Time')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_centers = []\n",
    "\n",
    "find_spike(signal, 0, noise_levels, fs, spike_centers, \n",
    "               window_size = 0.001, \n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = 4)\n",
    "\n",
    "spike_data = record_spikes(signal, fs, spike_centers, \n",
    "                  t_before = 0.001, \n",
    "                  t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0,3,4,2,4,5,3]\n",
    "np.percentile(a[1: 4], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (100,20))\n",
    "plt.plot(spike_data.index, spike_data.iloc[:,1])\n",
    "plt.xlabel('Time')\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
