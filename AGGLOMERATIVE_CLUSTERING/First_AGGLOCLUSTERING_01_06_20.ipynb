{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering\n",
    "\n",
    "### 01_06_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed for the tutorial\n",
    "\n",
    "# General syntax to import specific functions in a library: \n",
    "##from (library) import (specific library function)\n",
    "\n",
    "#from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "\n",
    "# General syntax to import a library but no functions: \n",
    "##import (library) as (give the library a nickname/alias)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "#import scipy.signal as signal\n",
    "from scipy.signal import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys  \n",
    "#sys.path.insert(0, '/Users/louiseplacidet/Desktop/PIR/GITPIR/GIT_29_04/PIR/AdabandFlt')\n",
    "#sys.path.insert(0, '/Users/SYL21/External_Drive/SUPAERO/PIR/AdabandFlt')\n",
    "sys.path.insert(0, '/Users/louiseplacidet/Desktop/PIR/GITPIR/GIT_29_04/PIR/AdabandFlt')\n",
    "#from AdaBandFlt import *\n",
    "#from V2AdaBandFlt import *\n",
    "from V3AdaBandFlt import *\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "# file path of csv file\n",
    "#Location = r'/Users/SYL21/External_Drive/SUPAERO/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/SYL21/External_Drive/SUPAERO/PIR/Data/Wetransfer_data/E18KABaseline_BcutV2groundAll.txt'\n",
    "Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_spike_data/newdata/E18KABaseline_BcutV2groundAll.txt'\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size_of_data = 1000000\n",
    "fs = 25000\n",
    "\n",
    "method_align = 'indice_1er_depass'\n",
    "time_before = 0.0015\n",
    "time_after = 0.0015\n",
    "\n",
    "threshold_factor = 3.2\n",
    "maxseparation = 0.0008\n",
    "\n",
    "#n_electrode = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering functions and cutoff frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 100.0\n",
    "highcut = 5000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%t</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.460009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>-0.962648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>-1.134794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.111801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>1.565317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.80</th>\n",
       "      <td>-5.186060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.84</th>\n",
       "      <td>-5.548677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.88</th>\n",
       "      <td>-4.637266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.92</th>\n",
       "      <td>-2.951045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.96</th>\n",
       "      <td>-1.074132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "%t                     \n",
       "0.00           0.460009\n",
       "0.04          -0.962648\n",
       "0.08          -1.134794\n",
       "0.12           0.111801\n",
       "0.16           1.565317\n",
       "...                 ...\n",
       "20799.80      -5.186060\n",
       "20799.84      -5.548677\n",
       "20799.88      -4.637266\n",
       "20799.92      -2.951045\n",
       "20799.96      -1.074132\n",
       "\n",
       "[520000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_to_filter = df.iloc[:,1] ## Electrode 31 (à vérifier)\n",
    "\n",
    "y = butter_bandpass_filter(signal_to_filter, lowcut, highcut, fs, order=6)\n",
    "\n",
    "filtereddf = pd.DataFrame(y)\n",
    "filtereddf.index = df.index\n",
    "\n",
    "filtereddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_filtered = filtereddf.iloc[:,0] ##selecting an electrode to use\n",
    "signal = filtereddf.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and Aligning the Spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Thresholds adapted to Noise Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.figure()\\nplt.plot(noise_levels)\\nplt.grid(True)\\nplt.xlabel('Time')\\nplt.ylabel('Noise Amplitude [µV]')\\nplt.title('Noise Levels')\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_levels = init_noise_levels(signal_filtered, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      estimator_type = \"RMS\",\n",
    "                      percentile_value = 25)\n",
    "\n",
    "\"\"\"plt.figure()\n",
    "plt.plot(noise_levels)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Noise Amplitude [µV]')\n",
    "plt.title('Noise Levels')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indice_min</th>\n",
       "      <th>indice_1er_depass</th>\n",
       "      <th>indice_max_gauche</th>\n",
       "      <th>indice_max_droite</th>\n",
       "      <th>Delta_amplitudes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13535</td>\n",
       "      <td>13535</td>\n",
       "      <td>nan</td>\n",
       "      <td>13545</td>\n",
       "      <td>14.273445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17663</td>\n",
       "      <td>17663</td>\n",
       "      <td>17653</td>\n",
       "      <td>nan</td>\n",
       "      <td>13.039536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17900</td>\n",
       "      <td>17900</td>\n",
       "      <td>17885</td>\n",
       "      <td>nan</td>\n",
       "      <td>13.301115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18807</td>\n",
       "      <td>18807</td>\n",
       "      <td>nan</td>\n",
       "      <td>18820</td>\n",
       "      <td>16.712292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37047</td>\n",
       "      <td>37047</td>\n",
       "      <td>37032</td>\n",
       "      <td>nan</td>\n",
       "      <td>15.256617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>489074</td>\n",
       "      <td>489073</td>\n",
       "      <td>489055</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.284391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>499254</td>\n",
       "      <td>499254</td>\n",
       "      <td>499250</td>\n",
       "      <td>nan</td>\n",
       "      <td>13.574724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>506210</td>\n",
       "      <td>506210</td>\n",
       "      <td>506192</td>\n",
       "      <td>nan</td>\n",
       "      <td>13.227750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>512271</td>\n",
       "      <td>512270</td>\n",
       "      <td>nan</td>\n",
       "      <td>512282</td>\n",
       "      <td>15.269442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>517077</td>\n",
       "      <td>517076</td>\n",
       "      <td>nan</td>\n",
       "      <td>517084</td>\n",
       "      <td>12.714262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indice_min  indice_1er_depass indice_max_gauche indice_max_droite  \\\n",
       "0         13535              13535               nan             13545   \n",
       "1         17663              17663             17653               nan   \n",
       "2         17900              17900             17885               nan   \n",
       "3         18807              18807               nan             18820   \n",
       "4         37047              37047             37032               nan   \n",
       "..          ...                ...               ...               ...   \n",
       "404      489074             489073            489055               nan   \n",
       "405      499254             499254            499250               nan   \n",
       "406      506210             506210            506192               nan   \n",
       "407      512271             512270               nan            512282   \n",
       "408      517077             517076               nan            517084   \n",
       "\n",
       "     Delta_amplitudes  \n",
       "0           14.273445  \n",
       "1           13.039536  \n",
       "2           13.301115  \n",
       "3           16.712292  \n",
       "4           15.256617  \n",
       "..                ...  \n",
       "404         16.284391  \n",
       "405         13.574724  \n",
       "406         13.227750  \n",
       "407         15.269442  \n",
       "408         12.714262  \n",
       "\n",
       "[409 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_info = find_spikes(signal, noise_levels, fs, \n",
    "                           window_size = 0.002, \n",
    "                           noise_window_size = 0.01,\n",
    "                           threshold_factor = threshold_factor,\n",
    "                           maxseparation = maxseparation)  \n",
    "                \n",
    "#spike_info.columns = ['indice_max','indice_min','indice_depass_positif','indice_depass_negatif', 'indice_1er_depass','indice_zero_central','i_max-i_min','Delta_amplitudes']\n",
    "spike_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 77)\n"
     ]
    }
   ],
   "source": [
    "spike_data = record_spikes(signal, fs, spike_info,\n",
    "                           method_align,\n",
    "                           t_before = time_before, \n",
    "                           t_after = time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_oneline = record_spikes_oneline(signal, fs, spike_info,\n",
    "                                           method_align,\n",
    "                                           t_before = time_before,\n",
    "                                           t_after = time_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.index, signal, color = 'blue')\n",
    "plt.plot(spike_data_oneline.index, spike_data_oneline, color = 'red')\n",
    "plt.title('Filtered Signal with Detected Spikes with RMS')\n",
    "plt.xlabel('Time Windows')\n",
    "plt.ylabel('Amplitude [µV]')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes(spike_data,\n",
    "             t_before_alignement = time_before,\n",
    "             first_spike = 1,\n",
    "             last_spike = 50,\n",
    "             fs = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilan PCA + AGGLOMERATIVE CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and AGGLOMERATIVE CLUSERING on spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_and_AGGLOCLUST_spikes(spike_data, spike_info, nb_PCA_components=3,\n",
    "                              n_clusters=5, metric='euclidean', linkage='ward'):\n",
    "    \n",
    "    ## on rééquilibre les valeurs dans les différentes dimensions\n",
    "    #pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    #pca_data = StandardScaler().fit_transform(pca_data) # normalizing the features\n",
    "    \n",
    "    ## PCA\n",
    "    pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    pca = PCA(n_components=nb_PCA_components)\n",
    "    pca.fit(pca_data)\n",
    "    PCA_X = pca.transform(pca_data)\n",
    "    \n",
    "    ## AGGLOMERATIVE CLUSTERING\n",
    "    ## Different linkages: 'ward', 'average', 'complete', 'single'\n",
    "    \n",
    "    aggloclustering = AgglomerativeClustering(n_clusters=n_clusters, affinity = metric,\n",
    "                                    linkage=linkage)\n",
    "    aggloclustering.fit(PCA_X)\n",
    "    \n",
    "    labels = aggloclustering.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    \n",
    "    ## Ajout du label des clusters dans spike info\n",
    "    spike_info['cluster_label'] = aggloclustering.labels_\n",
    "    \n",
    "    return PCA_X, aggloclustering, spike_info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering function info: \n",
    "AgglomerativeClustering(n_clusters=2, *, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward', distance_threshold=None)\n",
    "\n",
    "- affinity: “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”\n",
    "    NB: if linkage is ward: only \"euclidean\" is accepted\n",
    "- linkage{“ward”, “complete”, “average”, “single”}, default=”ward”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui plot la PCA\n",
    "\n",
    "def PCA_plot(PCA_X):\n",
    "    \n",
    "    fig = plt.figure(4,figsize=(4,3))\n",
    "    plt.clf()\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "    plt.cla()\n",
    "  \n",
    "    ax.scatter(PCA_X[:, 0], PCA_X[:, 1], PCA_X[:, 2], cmap=plt.cm.nipy_spectral,\n",
    "           edgecolor='k')\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the AGGLO CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui plot les clusters d'OPTICS\n",
    "\n",
    "def print_clusters_3d(labels, PCA_X):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    nb_clusters = max(labels) + 1\n",
    "\n",
    "    a = [i for i in range(len(labels))]\n",
    "    b = np.transpose([a,list(labels)])\n",
    "\n",
    "    for nb in range(nb_clusters):\n",
    "        legend = 'Cluster n°'+str(nb)\n",
    "        data = PCA_X[[x for x,y in b if y==nb],:]\n",
    "        ax.scatter(data[:,0], data[:,1], data[:,2],label=legend)\n",
    "    data = PCA_X[[x for x,y in b if y==-1],:]\n",
    "    ax.scatter(data[:,0], data[:,1], data[:,2], c='black',label='Noise cluster')    \n",
    "    \n",
    "    ax.set_title('Nombre de cluster(s) :' + str(nb_clusters))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#print_clusters_3d(kmeans.labels_, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the spikes from the different clusters after AGGLO CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spikes_clusterized(spike_data,\n",
    "                             labels,\n",
    "                             t_before_alignement = 0,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = -50,\n",
    "                             y_lim_max = 60,\n",
    "                             fs = 25000):\n",
    "    \n",
    "    nb_clusters = max(labels) + 1\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    #spike_data.iloc[:,first_spike:last_spike].plot()\n",
    "    t_b = int(np.round(fs*(t_before_alignement)))\n",
    "    y = (spike_data.iloc[:,0]-t_b)*1000/fs\n",
    "        \n",
    "    a = [i+1 for i in range(len(labels))]\n",
    "    b = np.transpose([a,list(labels)])\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        data = spike_data.iloc[:,[x for x,y in b if y==nb]]\n",
    "        m = len(data.values[0])\n",
    "        nb_spikes_in_cluster = len(data.columns)\n",
    "\n",
    "        \n",
    "        kept = []\n",
    "        \n",
    "        if m <= nb_spike:\n",
    "            kept = [i for i in range(m)]\n",
    "        else:      \n",
    "            i = 0  \n",
    "            while i < nb_spike:\n",
    "                r = randint(0,m-1)\n",
    "                if (r in kept) == False:\n",
    "                    kept.append(r)\n",
    "                    i += 1\n",
    "        \n",
    "        x = data.iloc[:,kept].values\n",
    "        axes = figure.add_subplot(nb_line, 2, nb+1)\n",
    "        axes.plot(y, x)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster numero ' + str(nb))\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid(True)\n",
    "        axes.legend([str(nb_spikes_in_cluster)+' spikes'])\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        data = spike_data.iloc[:,[x for x,y in b if y==-1]]\n",
    "        m = len(data.values[0])\n",
    "        nb_spikes_in_cluster = len(data.columns)\n",
    "    \n",
    "        kept = []\n",
    "        \n",
    "        if m <= nb_spike:\n",
    "            kept = [i for i in range(m)]\n",
    "        else:      \n",
    "            i = 0  \n",
    "            while i < nb_spike:\n",
    "                r = randint(0,m-1)\n",
    "                if (r in kept) == False:\n",
    "                    kept.append(r)\n",
    "                    i += 1\n",
    "        \n",
    "        x = data.iloc[:,kept].values\n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "        axes.plot(y, x)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster de bruit')\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid(True)\n",
    "        axes.legend([str(nb_spikes_in_cluster)+' spikes'])\n",
    "        \n",
    "#print_spikes_clusterized(spike_data,\n",
    "#                             dbscan.labels_,\n",
    "#                             t_before_alignement = 0.0015,\n",
    "#                             nb_spike = 20,\n",
    "#                             y_lim_min = -50,\n",
    "#                             y_lim_max = 60,\n",
    "#                             fs = 25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the spikes from clusters on original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui affiche les spikes des différents clusters sur échelle temporelle\n",
    "\n",
    "def print_spikes_clusterized_oneline(signal,\n",
    "                                     updated_spike_infos,\n",
    "                                     align_method = 'indice_zero_central',\n",
    "                                     t_before = 0.001,\n",
    "                                     t_after = 0.002,\n",
    "                                     fs = 25000,\n",
    "                                     y_lim_min = -50,\n",
    "                                     y_lim_max = 60,\n",
    "                                     separate_plot = False):\n",
    "    \n",
    "    labels = updated_spike_infos['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 2\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    ghost_array = np.array(['NaN' for x in range(len(signal))])\n",
    "    ghost_array = ghost_array.astype(float)\n",
    "    spike_data_clusterized_oneline = []\n",
    "    legend = ['Signald\\'origine']\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        \n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == nb],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+1)\n",
    "        axes.plot(signal.index, signal.values)\n",
    "        for ghost in range(nb):\n",
    "            axes.plot(signal.index, ghost_array)\n",
    "        axes.plot(signal.index, spike_data_oneline)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster n°' + str(nb))\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid()\n",
    "        \n",
    "        legend.append('Cluster n°' + str(nb))\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == -1],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "        axes.plot(signal.index, signal.values)\n",
    "        axes.plot(signal.index, spike_data_oneline)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster de bruit')\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid()\n",
    "                \n",
    "        legend.append('Cluster de bruit')\n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+3)\n",
    "    else:\n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "    \n",
    "    axes.plot(signal.index, signal.values)\n",
    "    axes.plot(signal.index, np.transpose(spike_data_clusterized_oneline))\n",
    "    axes.legend(legend)\n",
    "    axes.set_xlabel('Time in ms')\n",
    "    axes.set_title('Tous les clusters')\n",
    "    axes.set_ylim(y_lim_min , y_lim_max)\n",
    "    axes.grid()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#print_spikes_clusterized_oneline(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui affiche les spikes des différents clusters sur échelle temporelle\n",
    "\n",
    "def print_spikes_clusterized_oneline_total(signal,\n",
    "                                     updated_spike_infos,\n",
    "                                     align_method = 'indice_zero_central',\n",
    "                                     t_before = 0.001,\n",
    "                                     t_after = 0.002,\n",
    "                                     fs = 25000,\n",
    "                                     y_lim_min = -50,\n",
    "                                     y_lim_max = 60,\n",
    "                                     separate_plot = False):\n",
    "    \n",
    "    labels = updated_spike_infos['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 2\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    ghost_array = np.array(['NaN' for x in range(len(signal))])\n",
    "    ghost_array = ghost_array.astype(float)\n",
    "    spike_data_clusterized_oneline = []\n",
    "    legend = ['Signald\\'origine']\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        \n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == nb],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        legend.append('Cluster n°' + str(nb))\n",
    "\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == -1],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        legend.append('Cluster de bruit')\n",
    "    \n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    axes.plot(signal.index, signal.values)\n",
    "    axes.plot(signal.index, np.transpose(spike_data_clusterized_oneline))\n",
    "    axes.legend(legend)\n",
    "    axes.set_xlabel('Time in ms')\n",
    "    axes.set_title('Tous les clusters')\n",
    "    axes.set_ylim(y_lim_min , y_lim_max)\n",
    "    axes.grid()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#print_spikes_clusterized_oneline_total(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Amplitudes and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme de différences d'amplitude Peak-to-Peak des spikes\n",
    "\n",
    "def histogram_spikes_amplitude(spike_info):\n",
    "    plt.hist(spike_info['Delta_amplitudes'], bins='auto')\n",
    "    plt.title(\"Histogram of Spike Peak-to-Peak Amplitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme de l'écartement temporel des spikes (imax-imin)\n",
    "\n",
    "def histogram_spikes_time(spike_info):\n",
    "    plt.hist(spike_info['i_max-i_min'], bins='auto')\n",
    "    plt.title(\"Histogram of Spike i_max-i_min\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme des différences d'amplitude Peak-to-Peak des spikes:\n",
    "\n",
    "## ¡¡¡ATTENTION!!! Il faut que le spike info en entrée, soit mis à jour avec les labels des clusters\n",
    "\n",
    "def histogram_amplitude_clusterized(updated_spike_info):\n",
    "    \n",
    "    labels = updated_spike_info['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    for nb in range(nb_clusters):\n",
    "        local_info = spike_info.loc[spike_info['cluster_label'] == nb]\n",
    "        plt.figure()\n",
    "        plt.hist(local_info['cluster_label'], bins='auto')\n",
    "        plt.title(\"Histogram of Spike i_max-i_min of cluster n°\"+str(nb))\n",
    "        plt.show()\n",
    "    \n",
    "    if(-1 in labels) == True:\n",
    "        local_info = spike_info.loc[spike_info['cluster_label']==-1]\n",
    "        plt.figure()\n",
    "        plt.hist(local_info['cluster_label'], bins='auto')\n",
    "        plt.title(\"Histogram of Spike i_max-i_min of cluster of noise\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Function: PCA_and_AGGLOCLUST_spikes(spike_data, spike_info, nb_PCA_components=3,\n",
    "                                        #n_clusters=5,metric = 'euclidean',linkage='ward')\n",
    "\n",
    "PCA_X, aggloclustering, updated_spike_info = PCA_and_AGGLOCLUST_spikes(spike_data,\n",
    "                                                                       spike_info, nb_PCA_components=3,\n",
    "                                                                       n_clusters=5, metric=\"euclidean\", \n",
    "                                                                       linkage=\"ward\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggloclustering.labels_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: PCA_plot(spike_data, nb_clusters=3)\n",
    "\n",
    "PCA_plot(PCA_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_clusters_3d(labels, PCA_X)\n",
    "\n",
    "print_clusters_3d(aggloclustering.labels_, PCA_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized(spike_data,\n",
    "#                             labels,\n",
    "#                             t_before_alignement = 0.0015,\n",
    "#                             nb_spike = 20,\n",
    "#                             y_lim_min = -50,\n",
    "#                             y_lim_max = 60,\n",
    "#                             fs = 25000)\n",
    "                        \n",
    "print_spikes_clusterized(spike_data,\n",
    "                             aggloclustering.labels_,\n",
    "                             t_before_alignement = time_before,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = -50,\n",
    "                             y_lim_max = 60,\n",
    "                             fs = fs)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized_oneline(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline(signal,\n",
    "                                 updated_spike_info,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized_oneline_total(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline_total(signal,\n",
    "                                 updated_spike_info,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: histogram_spikes_amplitude(spike_info)\n",
    "\n",
    "histogram_spikes_amplitude(spike_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'i_max-i_min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'i_max-i_min'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ed931cea391c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function: histogram_spikes_time(spike_info)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistogram_spikes_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-c02ff7880388>\u001b[0m in \u001b[0;36mhistogram_spikes_time\u001b[0;34m(spike_info)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhistogram_spikes_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i_max-i_min'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Histogram of Spike i_max-i_min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'i_max-i_min'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:1705: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  return self.func(*args)\n"
     ]
    }
   ],
   "source": [
    "# Function: histogram_spikes_time(spike_info)\n",
    "\n",
    "histogram_spikes_time(spike_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: histogram_amplitude_clusterized(spike_info)\n",
    "\n",
    "histogram_amplitude_clusterized(updated_spike_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
