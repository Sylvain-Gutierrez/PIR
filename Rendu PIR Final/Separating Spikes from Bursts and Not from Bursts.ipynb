{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys \n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../packaging_PIR')\n",
    "from neural_data_treatment_pkg.PrintFunctions import *\n",
    "from neural_data_treatment_pkg.AdaBandFlt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "# Enable outline plotting\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading (execute only the one corresponding to your device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path of csv file\n",
    "\n",
    "Location = r'/Users/sylva/Documents/SUPAERO/2A/PIR/Data/Wetransfer_data/E18KABaseline_BcutV2groundAll.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_spike_data/newdata/E18KABaseline_BcutV2groundAll.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete this one with your own path\n",
    "\n",
    "#Location = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['El 21       ', 'El 31       ', 'El 41       ', 'El 22       ',\n",
       "       'El 32       ', 'El 42       ', 'El 23       ', 'El 33       ',\n",
       "       'El 43       ', 'El 15       '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the sampling frequency and the alignement method for the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 25000\n",
    "align_method = 'indice_1er_depass'\n",
    "y_lim_min = -25\n",
    "y_lim_max = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuting and filtering the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sylva\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################################\n",
    "####  BANK OF PARTS OF DATA\n",
    "size = 1000000\n",
    "all_raw_data = df #Entire recording from all electrodes\n",
    "\n",
    "#full_signal = df.iloc[:,1] #Entire recording from electrode 58\n",
    "full_signal = df.loc[:size,'El 31       '] #Entire recording from electrode 58\n",
    "\n",
    "electrode_ref = df.loc[:size,'El 15       ']\n",
    "\n",
    "# Desired cutoff frequencies (in Hz).\n",
    "lowcut = 100.0\n",
    "highcut = 5000.0\n",
    "\n",
    "#y = butter_bandpass_filter(df.iloc[:,1], lowcut, highcut, fs, order=6)\n",
    "y = butter_bandpass_filter(df.iloc[:size,6], lowcut, highcut, fs, order=5)\n",
    "y_ref = butter_bandpass_filter(df.iloc[:size,8],lowcut,highcut,fs,order=5)\n",
    "\n",
    "filtereddf = pd.DataFrame(y)\n",
    "filtereddf.index = df.index[:size]\n",
    "\n",
    "filtereddf_ref = pd.DataFrame(y_ref)\n",
    "filtereddf_ref.index = df.index[:size]\n",
    "\n",
    "\n",
    "signal_filtered = filtereddf.iloc[:,0] #Entire recording filtered by bandpass, for one electrode\n",
    "signal_filtered_ref = filtereddf_ref.iloc[:,0]\n",
    "\n",
    "\n",
    "###########################\n",
    "## Signal de 20s\n",
    "\n",
    "xminspike = int(np.round(12548*(fs/1000)))\n",
    "xmaxspike = int(np.round(13000*(fs/1000)))\n",
    "\n",
    "burst_data = filtereddf.iloc[xminspike:xmaxspike,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting the signal or the part of the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = signal_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the noise initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = init_noise_levels(signal_filtered, fs, \n",
    "                                  noise_window_size = 0.01,\n",
    "                                  required_valid_windows = 20,\n",
    "                                  old_noise_level_propagation = 0.8, \n",
    "                                  test_level = 5,\n",
    "                                  estimator_type = \"RMS\",\n",
    "                                  percentile_value = 25,\n",
    "                                  plot_estimator_graph = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_info = find_spikes(signal, noise_levels, fs,\n",
    "                           window_size = 0.002,\n",
    "                           noise_window_size = 0.01,\n",
    "                           threshold_factor = 3.5,\n",
    "                           positive_threshold_factor = 0.33,\n",
    "                           maxseparation = 0.001,\n",
    "                           time_checkmaxlocal = 0.0002,\n",
    "                           burst_threshold = 7)\n",
    "\n",
    "spike_fine_tuning(spike_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_burst = record_spikes(signal, fs, spike_info.loc[spike_info['burst?'] == True],\n",
    "                              align_method,\n",
    "                              t_before = 0.001,\n",
    "                              t_after = 0.002)\n",
    "\n",
    "spike_data_no_burst = record_spikes(signal, fs, spike_info.loc[spike_info['burst?'] == False],\n",
    "                              align_method,\n",
    "                              t_before = 0.001,\n",
    "                              t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes(spike_data_burst,\n",
    "             t_before_alignement = 0,\n",
    "             first_spike = 0,\n",
    "             last_spike = -1,\n",
    "             fs = fs,\n",
    "             randomize = True,\n",
    "             nb_spike = 20,\n",
    "             y_lim_min = y_lim_min,\n",
    "             y_lim_max = y_lim_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes(spike_data_no_burst,\n",
    "             t_before_alignement = 0,\n",
    "             first_spike = 0,\n",
    "             last_spike = -1,\n",
    "             fs = fs,\n",
    "             randomize = True,\n",
    "             nb_spike = 20,\n",
    "             y_lim_min = y_lim_min,\n",
    "             y_lim_max = y_lim_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_oneline_burst = record_spikes_oneline(signal, fs, spike_info.loc[spike_info['burst?'] == True],\n",
    "                                                  align_method,\n",
    "                                                  t_before = 0.001,\n",
    "                                                  t_after = 0.002)\n",
    "\n",
    "spike_data_oneline_no_burst = record_spikes_oneline(signal, fs, spike_info.loc[spike_info['burst?'] == False],\n",
    "                                                  align_method,\n",
    "                                                  t_before = 0.001,\n",
    "                                                  t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes_oneline(signal, spike_data_oneline_burst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes_oneline(signal, spike_data_oneline_no_burst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilan PCA + AGGLOMERATIVE CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and AGGLOMERATIVE CLUSERING on spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_and_AGGLOCLUST_spikes(spike_data, spike_info, nb_PCA_components=3,\n",
    "                              n_clusters=5, metric='euclidean', linkage='ward'):\n",
    "    \n",
    "    ## on rééquilibre les valeurs dans les différentes dimensions\n",
    "    #pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    #pca_data = StandardScaler().fit_transform(pca_data) # normalizing the features\n",
    "    \n",
    "    ## PCA\n",
    "    pca_data = np.array(spike_data.values).transpose()\n",
    "    pca = PCA(n_components=nb_PCA_components)\n",
    "    pca.fit(pca_data)\n",
    "    PCA_X = pca.transform(pca_data)\n",
    "    \n",
    "    ## AGGLOMERATIVE CLUSTERING\n",
    "    ## Different linkages: 'ward', 'average', 'complete', 'single'\n",
    "    \n",
    "    aggloclustering = AgglomerativeClustering(n_clusters=n_clusters, affinity = metric,\n",
    "                                    linkage=linkage)\n",
    "    aggloclustering.fit(PCA_X)\n",
    "    \n",
    "    labels = aggloclustering.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    \n",
    "    ## Ajout du label des clusters dans spike info\n",
    "    spike_info['cluster_label'] = aggloclustering.labels_\n",
    "    \n",
    "    return PCA_X, aggloclustering, spike_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sylva\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "PCA_X, aggloclustering, updated_spike_info = PCA_and_AGGLOCLUST_spikes(spike_data_burst,\n",
    "                                                                        spike_info.loc[spike_info['burst?'] == True], \n",
    "                                                                        nb_PCA_components=3,\n",
    "                                                                        n_clusters=5, \n",
    "                                                                        metric=\"euclidean\", \n",
    "                                                                        linkage=\"ward\")\n",
    "labels = aggloclustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sylva\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "PCA_X_, aggloclustering_, updated_spike_info_ = PCA_and_AGGLOCLUST_spikes(spike_data_no_burst,\n",
    "                                                                        spike_info.loc[spike_info['burst?'] == False], \n",
    "                                                                        nb_PCA_components=3,\n",
    "                                                                        n_clusters=5, \n",
    "                                                                        metric=\"euclidean\", \n",
    "                                                                        linkage=\"ward\")\n",
    "labels_ = aggloclustering_.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_plot(PCA_X)\n",
    "print_clusters_3d(labels, PCA_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_plot(PCA_X_)\n",
    "print_clusters_3d(labels_, PCA_X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the spikes clusterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes_clusterized(spike_data_burst,\n",
    "                             labels,\n",
    "                             t_before_alignement = 0.001,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = y_lim_min,\n",
    "                             y_lim_max = y_lim_max,\n",
    "                             fs = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes_clusterized(spike_data_no_burst,\n",
    "                             labels_,\n",
    "                             t_before_alignement = 0.001,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = y_lim_min,\n",
    "                             y_lim_max = y_lim_max,\n",
    "                             fs = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels located in labels will be used\n"
     ]
    }
   ],
   "source": [
    "spike_data_clusterized_oneline_burst = record_spikes_clusterized_oneline(signal, \n",
    "                                                                      fs, \n",
    "                                                                      updated_spike_info,\n",
    "                                                                      align_method,\n",
    "                                                                       labels,\n",
    "                                                                      t_before = 0.001,\n",
    "                                                                      t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels located in labels will be used\n"
     ]
    }
   ],
   "source": [
    "spike_data_clusterized_oneline_no_burst = record_spikes_clusterized_oneline(signal, \n",
    "                                                                      fs, \n",
    "                                                                      updated_spike_info_,\n",
    "                                                                      align_method,\n",
    "                                                                       labels_,\n",
    "                                                                      t_before = 0.001,\n",
    "                                                                      t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes_clusterized_oneline(signal, spike_data_clusterized_oneline_burst,\n",
    "                             y_lim_min = y_lim_min,\n",
    "                             y_lim_max = y_lim_max,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes_clusterized_oneline(signal, spike_data_clusterized_oneline_no_burst,\n",
    "                             y_lim_min = y_lim_min,\n",
    "                             y_lim_max = y_lim_max,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
