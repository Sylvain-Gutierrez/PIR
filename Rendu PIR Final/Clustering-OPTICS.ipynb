{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OPTICS' from 'sklearn.cluster' (C:\\Users\\sylva\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f6b4270597cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOPTICS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OPTICS' from 'sklearn.cluster' (C:\\Users\\sylva\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import all libraries needed \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys \n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../packaging_PIR')\n",
    "from neural_data_treatment_pkg.PrintFunctions import *\n",
    "from neural_data_treatment_pkg.AdaBandFlt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "# Enable outline plotting\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading (execute only the one corresponding to your device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path of csv file\n",
    "\n",
    "Location = r'/Users/sylva/Documents/SUPAERO/2A/PIR/Data/data_no_burst/539W6cbaseRaw.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_spike_data/newdata/E18KABaseline_BcutV2groundAll.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete this one with your own path\n",
    "\n",
    "#Location = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sylva\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['El 41       ', 'El 42       ', 'El 44       ', 'El 54       ',\n",
       "       'El 55       ', 'El 56       ', 'El 58       ', 'El 86       ',\n",
       "       'El 15       ', 'El 51       '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the sampling frequency and the alignement method for the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 50000\n",
    "align_method = 'indice_1er_depass'\n",
    "y_lim_min = -25\n",
    "y_lim_max = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuting and filtering the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sylva\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################################\n",
    "####  BANK OF PARTS OF DATA\n",
    "size = 1000000\n",
    "all_raw_data = df #Entire recording from all electrodes\n",
    "\n",
    "#full_signal = df.iloc[:,1] #Entire recording from electrode 58\n",
    "full_signal = df.loc[:size,'El 58       '] #Entire recording from electrode 58\n",
    "\n",
    "electrode_ref = df.loc[:size,'El 15       ']\n",
    "\n",
    "# Desired cutoff frequencies (in Hz).\n",
    "lowcut = 100.0\n",
    "highcut = 5000.0\n",
    "\n",
    "#y = butter_bandpass_filter(df.iloc[:,1], lowcut, highcut, fs, order=6)\n",
    "y = butter_bandpass_filter(df.iloc[:size,6], lowcut, highcut, fs, order=5)\n",
    "y_ref = butter_bandpass_filter(df.iloc[:size,8],lowcut,highcut,fs,order=5)\n",
    "\n",
    "filtereddf = pd.DataFrame(y)\n",
    "filtereddf.index = df.index[:size]\n",
    "\n",
    "filtereddf_ref = pd.DataFrame(y_ref)\n",
    "filtereddf_ref.index = df.index[:size]\n",
    "\n",
    "\n",
    "signal_filtered = filtereddf.iloc[:,0] #Entire recording filtered by bandpass, for one electrode\n",
    "signal_filtered_ref = filtereddf_ref.iloc[:,0]\n",
    "\n",
    "\n",
    "###########################\n",
    "## Signal de 20s\n",
    "\n",
    "xminspike = int(np.round(12548*(fs/1000)))\n",
    "xmaxspike = int(np.round(13000*(fs/1000)))\n",
    "\n",
    "burst_data = filtereddf.iloc[xminspike:xmaxspike,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting the signal or the part of the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = signal_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the noise initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = init_noise_levels(signal_filtered, fs, \n",
    "                                  noise_window_size = 0.01,\n",
    "                                  required_valid_windows = 20,\n",
    "                                  old_noise_level_propagation = 0.8, \n",
    "                                  test_level = 5,\n",
    "                                  estimator_type = \"RMS\",\n",
    "                                  percentile_value = 25,\n",
    "                                  plot_estimator_graph = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_info = find_spikes(signal, noise_levels, fs,\n",
    "                           window_size = 0.002,\n",
    "                           noise_window_size = 0.01,\n",
    "                           threshold_factor = 3.5,\n",
    "                           positive_threshold_factor = 0.33,\n",
    "                           maxseparation = 0.001,\n",
    "                           time_checkmaxlocal = 0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data = record_spikes(signal, fs, spike_info,\n",
    "                              align_method,\n",
    "                              t_before = 0.001,\n",
    "                              t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes(spike_data,\n",
    "             t_before_alignement = 0,\n",
    "             first_spike = 0,\n",
    "             last_spike = -1,\n",
    "             fs = fs,\n",
    "             randomize = True,\n",
    "             nb_spike = 20,\n",
    "             y_lim_min = y_lim_min,\n",
    "             y_lim_max = y_lim_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_oneline = record_spikes_oneline(signal, fs, spike_info,\n",
    "                                              align_method,\n",
    "                                              t_before = 0.001,\n",
    "                                              t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes_oneline(signal, spike_data_oneline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilan PCA + OPTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and OPTICS on spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def PCA_and_OPTICS_spikes(spike_data, spike_info, nb_PCA_components=3, min_samples=5, max_eps=10, xi=0.05,min_cluster_size=5):\n",
    "    \n",
    "    ## on rééquilibre les valeurs dans les différentes dimensions\n",
    "    #pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    #pca_data = StandardScaler().fit_transform(pca_data) # normalizing the features\n",
    "    \n",
    "    ## PCA\n",
    "    pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    pca = PCA(n_components=nb_PCA_components)\n",
    "    pca.fit(pca_data)\n",
    "    PCA_X = pca.transform(pca_data)\n",
    "    \n",
    "    ## OPTICS\n",
    "    \n",
    "    optics = OPTICS(min_samples=min_samples, max_eps=max_eps, xi=0.05,min_cluster_size=min_cluster_size).fit(PCA_X)\n",
    "\n",
    "    #core_samples_mask = np.zeros_like(optics.labels_, dtype=bool)\n",
    "    #core_samples_mask[optics.core_sample_indices_] = True\n",
    "    labels = optics.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "    print('')\n",
    "    print('Number of spikes detected by AdaBandFlt: %d' % len(spike_info))\n",
    "    print('Spikes placed into the clusters: %d' % (len(spike_info)-n_noise_))\n",
    "    print('Percentage placed: %d ' % ((len(spike_info)-n_noise_)/len(spike_info)*100))\n",
    "    \n",
    "    ## Ajout du label des clusters dans spike info\n",
    "    spike_info['cluster_label'] = optics.labels_\n",
    "    \n",
    "    return PCA_X, optics, spike_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 13\n",
      "Estimated number of noise points: 333\n",
      "\n",
      "Number of spikes detected by AdaBandFlt: 389\n",
      "Spikes placed into the clusters: 56\n",
      "Percentage placed: 14 \n"
     ]
    }
   ],
   "source": [
    "PCA_X, optics, updated_spike_info = PCA_and_OPTICS_spikes(spike_data, spike_info,5,3,500,0.05,3)\n",
    "labels = optics.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_plot(PCA_X)\n",
    "print_clusters_3d(labels, PCA_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the spikes clusterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes_clusterized(spike_data,\n",
    "                             labels,\n",
    "                             t_before_alignement = 0.001,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = y_lim_min,\n",
    "                             y_lim_max = y_lim_max,\n",
    "                             fs = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels located in labels will be used\n"
     ]
    }
   ],
   "source": [
    "spike_data_clusterized_oneline = record_spikes_clusterized_oneline(signal, \n",
    "                                                                      fs, \n",
    "                                                                      spike_info,\n",
    "                                                                      align_method,\n",
    "                                                                       labels,\n",
    "                                                                      t_before = 0.001,\n",
    "                                                                      t_after = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes_clusterized_oneline(signal, spike_data_clusterized_oneline,\n",
    "                             y_lim_min = y_lim_min,\n",
    "                             y_lim_max = y_lim_max,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
