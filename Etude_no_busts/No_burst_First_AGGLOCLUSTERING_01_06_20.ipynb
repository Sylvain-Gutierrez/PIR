{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering\n",
    "\n",
    "### 01_06_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed for the tutorial\n",
    "\n",
    "# General syntax to import specific functions in a library: \n",
    "##from (library) import (specific library function)\n",
    "\n",
    "#from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "\n",
    "# General syntax to import a library but no functions: \n",
    "##import (library) as (give the library a nickname/alias)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "#import scipy.signal as signal\n",
    "from scipy.signal import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys  \n",
    "#sys.path.insert(0, '/Users/louiseplacidet/Desktop/PIR/GITPIR/GIT_29_04/PIR/AdabandFlt')\n",
    "#sys.path.insert(0, '/Users/SYL21/External_Drive/SUPAERO/PIR/AdabandFlt')\n",
    "sys.path.insert(0, '/Users/louiseplacidet/Desktop/PIR/GITPIR/GIT_29_04/PIR/AdabandFlt')\n",
    "#from AdaBandFlt import *\n",
    "#from V2AdaBandFlt import *\n",
    "from V3AdaBandFlt import *\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "# file path of csv file\n",
    "#Location = r'/Users/SYL21/External_Drive/SUPAERO/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/SYL21/External_Drive/SUPAERO/PIR/Data/Wetransfer_data/E18KABaseline_BcutV2groundAll.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_spike_data/newdata/E18KABaseline_BcutV2groundAll.txt'\n",
    "Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_new_spike_data/539W6cbaseRaw.txt'\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_data = 1000000\n",
    "fs = 50000\n",
    "\n",
    "method_align = 'indice_1er_depass'\n",
    "time_before = 0.0015\n",
    "time_after = 0.0015\n",
    "\n",
    "threshold_factor = 3.5\n",
    "maxseparation = 0.0008\n",
    "\n",
    "#n_electrode = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering functions and cutoff frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 100.0\n",
    "highcut = 5000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%t</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.898347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>-1.423672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>-3.482439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>-5.068991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>-6.071031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999.90</th>\n",
       "      <td>-5.381811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999.92</th>\n",
       "      <td>-4.461242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999.94</th>\n",
       "      <td>-3.219172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999.96</th>\n",
       "      <td>-1.725554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999.98</th>\n",
       "      <td>-0.094697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "%t                     \n",
       "0.00           0.898347\n",
       "0.02          -1.423672\n",
       "0.04          -3.482439\n",
       "0.06          -5.068991\n",
       "0.08          -6.071031\n",
       "...                 ...\n",
       "299999.90     -5.381811\n",
       "299999.92     -4.461242\n",
       "299999.94     -3.219172\n",
       "299999.96     -1.725554\n",
       "299999.98     -0.094697\n",
       "\n",
       "[15000000 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_to_filter = df.iloc[:size_of_data,6] #Electrode 58\n",
    "\n",
    "y = butter_bandpass_filter(signal_to_filter, lowcut, highcut, fs, order=6)\n",
    "\n",
    "filtereddf = pd.DataFrame(y)\n",
    "filtereddf.index = df.index\n",
    "\n",
    "filtereddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_filtered = filtereddf.iloc[:,0]\n",
    "signal = filtereddf.iloc[:,0] ##selecting an electrode to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and Aligning the Spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Thresholds adapted to Noise Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = init_noise_levels(signal_filtered, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      estimator_type = \"RMS\",\n",
    "                      percentile_value = 25)\n",
    "\n",
    "#plt.figure()\n",
    "#plt.plot(noise_levels)\n",
    "#plt.grid(True)\n",
    "#plt.xlabel('Time')\n",
    "#plt.ylabel('Noise Amplitude [µV]')\n",
    "#plt.title('Noise Levels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indice_min</th>\n",
       "      <th>indice_1er_depass</th>\n",
       "      <th>indice_max_gauche</th>\n",
       "      <th>indice_max_droite</th>\n",
       "      <th>Delta_amplitudes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48001</td>\n",
       "      <td>48001</td>\n",
       "      <td>47964</td>\n",
       "      <td>nan</td>\n",
       "      <td>20.420455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51265</td>\n",
       "      <td>51264</td>\n",
       "      <td>51253</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.810932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127483</td>\n",
       "      <td>127482</td>\n",
       "      <td>127465</td>\n",
       "      <td>nan</td>\n",
       "      <td>17.072964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176846</td>\n",
       "      <td>176845</td>\n",
       "      <td>nan</td>\n",
       "      <td>176880</td>\n",
       "      <td>19.056821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183942</td>\n",
       "      <td>183941</td>\n",
       "      <td>nan</td>\n",
       "      <td>183969</td>\n",
       "      <td>17.201650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>14770249</td>\n",
       "      <td>14770246</td>\n",
       "      <td>14770232</td>\n",
       "      <td>nan</td>\n",
       "      <td>19.070289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>14864191</td>\n",
       "      <td>14864189</td>\n",
       "      <td>14864177</td>\n",
       "      <td>nan</td>\n",
       "      <td>18.929579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>14897921</td>\n",
       "      <td>14897920</td>\n",
       "      <td>14897884</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.825488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>14925034</td>\n",
       "      <td>14925032</td>\n",
       "      <td>nan</td>\n",
       "      <td>14925068</td>\n",
       "      <td>19.215302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>14951871</td>\n",
       "      <td>14951871</td>\n",
       "      <td>14951855</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.180030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indice_min  indice_1er_depass indice_max_gauche indice_max_droite  \\\n",
       "0         48001              48001             47964               nan   \n",
       "1         51265              51264             51253               nan   \n",
       "2        127483             127482            127465               nan   \n",
       "3        176846             176845               nan            176880   \n",
       "4        183942             183941               nan            183969   \n",
       "..          ...                ...               ...               ...   \n",
       "373    14770249           14770246          14770232               nan   \n",
       "374    14864191           14864189          14864177               nan   \n",
       "375    14897921           14897920          14897884               nan   \n",
       "376    14925034           14925032               nan          14925068   \n",
       "377    14951871           14951871          14951855               nan   \n",
       "\n",
       "     Delta_amplitudes  \n",
       "0           20.420455  \n",
       "1           16.810932  \n",
       "2           17.072964  \n",
       "3           19.056821  \n",
       "4           17.201650  \n",
       "..                ...  \n",
       "373         19.070289  \n",
       "374         18.929579  \n",
       "375         16.825488  \n",
       "376         19.215302  \n",
       "377         16.180030  \n",
       "\n",
       "[378 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_info = find_spikes(signal, noise_levels, fs, \n",
    "                           window_size = 0.002, \n",
    "                           noise_window_size = 0.01,\n",
    "                           threshold_factor = threshold_factor,\n",
    "                           maxseparation = maxseparation)  \n",
    "                \n",
    "#spike_info.columns = ['indice_max','indice_min','indice_depass_positif','indice_depass_negatif', 'indice_1er_depass','indice_zero_central','i_max-i_min','Delta_amplitudes']\n",
    "spike_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 151)\n"
     ]
    }
   ],
   "source": [
    "spike_data = record_spikes(signal, fs, spike_info,\n",
    "                           method_align,\n",
    "                           t_before = time_before, \n",
    "                           t_after = time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_oneline = record_spikes_oneline(signal, fs, spike_info,\n",
    "                                           method_align,\n",
    "                                           t_before = time_before,\n",
    "                                           t_after = time_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.index, signal, color = 'blue')\n",
    "plt.plot(spike_data_oneline.index, spike_data_oneline, color = 'red')\n",
    "plt.title('Filtered Signal with Detected Spikes with RMS')\n",
    "plt.xlabel('Time Windows')\n",
    "plt.ylabel('Amplitude [µV]')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes(spike_data,\n",
    "             t_before_alignement = time_before,\n",
    "             first_spike = 1,\n",
    "             last_spike = 50,\n",
    "             fs = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilan PCA + AGGLOMERATIVE CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and AGGLOMERATIVE CLUSERING on spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_and_AGGLOCLUST_spikes(spike_data, spike_info, nb_PCA_components=3,\n",
    "                              n_clusters=5, metric='euclidean', linkage='ward'):\n",
    "    \n",
    "    ## on rééquilibre les valeurs dans les différentes dimensions\n",
    "    #pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    #pca_data = StandardScaler().fit_transform(pca_data) # normalizing the features\n",
    "    \n",
    "    ## PCA\n",
    "    pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    pca = PCA(n_components=nb_PCA_components)\n",
    "    pca.fit(pca_data)\n",
    "    PCA_X = pca.transform(pca_data)\n",
    "    \n",
    "    ## AGGLOMERATIVE CLUSTERING\n",
    "    ## Different linkages: 'ward', 'average', 'complete', 'single'\n",
    "    \n",
    "    aggloclustering = AgglomerativeClustering(n_clusters=n_clusters, affinity = metric,\n",
    "                                    linkage=linkage)\n",
    "    aggloclustering.fit(PCA_X)\n",
    "    \n",
    "    labels = aggloclustering.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    \n",
    "    ## Ajout du label des clusters dans spike info\n",
    "    spike_info['cluster_label'] = aggloclustering.labels_\n",
    "    \n",
    "    return PCA_X, aggloclustering, spike_info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering function info: \n",
    "AgglomerativeClustering(n_clusters=2, *, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward', distance_threshold=None)\n",
    "\n",
    "- affinity: “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”\n",
    "    NB: if linkage is ward: only \"euclidean\" is accepted\n",
    "- linkage{“ward”, “complete”, “average”, “single”}, default=”ward”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui plot la PCA\n",
    "\n",
    "def PCA_plot(PCA_X):\n",
    "    \n",
    "    fig = plt.figure(4,figsize=(4,3))\n",
    "    plt.clf()\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "    plt.cla()\n",
    "  \n",
    "    ax.scatter(PCA_X[:, 0], PCA_X[:, 1], PCA_X[:, 2], cmap=plt.cm.nipy_spectral,\n",
    "           edgecolor='k')\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the AGGLO CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui plot les clusters d'OPTICS\n",
    "\n",
    "def print_clusters_3d(labels, PCA_X):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    nb_clusters = max(labels) + 1\n",
    "\n",
    "    a = [i for i in range(len(labels))]\n",
    "    b = np.transpose([a,list(labels)])\n",
    "\n",
    "    for nb in range(nb_clusters):\n",
    "        legend = 'Cluster n°'+str(nb)\n",
    "        data = PCA_X[[x for x,y in b if y==nb],:]\n",
    "        ax.scatter(data[:,0], data[:,1], data[:,2],label=legend)\n",
    "    data = PCA_X[[x for x,y in b if y==-1],:]\n",
    "    ax.scatter(data[:,0], data[:,1], data[:,2], c='black',label='Noise cluster')    \n",
    "    \n",
    "    ax.set_title('Nombre de cluster(s) :' + str(nb_clusters))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#print_clusters_3d(kmeans.labels_, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the spikes from the different clusters after OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spikes_clusterized(spike_data,\n",
    "                             labels,\n",
    "                             t_before_alignement = 0,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = -50,\n",
    "                             y_lim_max = 60,\n",
    "                             fs = 25000):\n",
    "    \n",
    "    nb_clusters = max(labels) + 1\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    #spike_data.iloc[:,first_spike:last_spike].plot()\n",
    "    t_b = int(np.round(fs*(t_before_alignement)))\n",
    "    y = (spike_data.iloc[:,0]-t_b)*1000/fs\n",
    "        \n",
    "    a = [i+1 for i in range(len(labels))]\n",
    "    b = np.transpose([a,list(labels)])\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        data = spike_data.iloc[:,[x for x,y in b if y==nb]]\n",
    "        m = len(data.values[0])\n",
    "        nb_spikes_in_cluster = len(data.columns)\n",
    "\n",
    "        \n",
    "        kept = []\n",
    "        \n",
    "        if m <= nb_spike:\n",
    "            kept = [i for i in range(m)]\n",
    "        else:      \n",
    "            i = 0  \n",
    "            while i < nb_spike:\n",
    "                r = randint(0,m-1)\n",
    "                if (r in kept) == False:\n",
    "                    kept.append(r)\n",
    "                    i += 1\n",
    "        \n",
    "        x = data.iloc[:,kept].values\n",
    "        axes = figure.add_subplot(nb_line, 2, nb+1)\n",
    "        axes.plot(y, x)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster numero ' + str(nb))\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid(True)\n",
    "        axes.legend([str(nb_spikes_in_cluster)+' spikes'])\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        data = spike_data.iloc[:,[x for x,y in b if y==-1]]\n",
    "        m = len(data.values[0])\n",
    "        nb_spikes_in_cluster = len(data.columns)\n",
    "    \n",
    "        kept = []\n",
    "        \n",
    "        if m <= nb_spike:\n",
    "            kept = [i for i in range(m)]\n",
    "        else:      \n",
    "            i = 0  \n",
    "            while i < nb_spike:\n",
    "                r = randint(0,m-1)\n",
    "                if (r in kept) == False:\n",
    "                    kept.append(r)\n",
    "                    i += 1\n",
    "        \n",
    "        x = data.iloc[:,kept].values\n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "        axes.plot(y, x)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster de bruit')\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid(True)\n",
    "        axes.legend([str(nb_spikes_in_cluster)+' spikes'])\n",
    "        \n",
    "#print_spikes_clusterized(spike_data,\n",
    "#                             dbscan.labels_,\n",
    "#                             t_before_alignement = 0.0015,\n",
    "#                             nb_spike = 20,\n",
    "#                             y_lim_min = -50,\n",
    "#                             y_lim_max = 60,\n",
    "#                             fs = 25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the spikes from clusters on original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui affiche les spikes des différents clusters sur échelle temporelle\n",
    "\n",
    "def print_spikes_clusterized_oneline(signal,\n",
    "                                     updated_spike_infos,\n",
    "                                     align_method = 'indice_zero_central',\n",
    "                                     t_before = 0.001,\n",
    "                                     t_after = 0.002,\n",
    "                                     fs = 25000,\n",
    "                                     y_lim_min = -50,\n",
    "                                     y_lim_max = 60,\n",
    "                                     separate_plot = False):\n",
    "    \n",
    "    labels = updated_spike_infos['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 2\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    ghost_array = np.array(['NaN' for x in range(len(signal))])\n",
    "    ghost_array = ghost_array.astype(float)\n",
    "    spike_data_clusterized_oneline = []\n",
    "    legend = ['Signald\\'origine']\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        \n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == nb],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+1)\n",
    "        axes.plot(signal.index, signal.values)\n",
    "        for ghost in range(nb):\n",
    "            axes.plot(signal.index, ghost_array)\n",
    "        axes.plot(signal.index, spike_data_oneline)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster n°' + str(nb))\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid()\n",
    "        \n",
    "        legend.append('Cluster n°' + str(nb))\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == -1],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "        axes.plot(signal.index, signal.values)\n",
    "        axes.plot(signal.index, spike_data_oneline)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster de bruit')\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid()\n",
    "                \n",
    "        legend.append('Cluster de bruit')\n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+3)\n",
    "    else:\n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "    \n",
    "    axes.plot(signal.index, signal.values)\n",
    "    axes.plot(signal.index, np.transpose(spike_data_clusterized_oneline))\n",
    "    axes.legend(legend)\n",
    "    axes.set_xlabel('Time in ms')\n",
    "    axes.set_title('Tous les clusters')\n",
    "    axes.set_ylim(y_lim_min , y_lim_max)\n",
    "    axes.grid()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#print_spikes_clusterized_oneline(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui affiche les spikes des différents clusters sur échelle temporelle\n",
    "\n",
    "def print_spikes_clusterized_oneline_total(signal,\n",
    "                                     updated_spike_infos,\n",
    "                                     align_method = 'indice_zero_central',\n",
    "                                     t_before = 0.001,\n",
    "                                     t_after = 0.002,\n",
    "                                     fs = 25000,\n",
    "                                     y_lim_min = -50,\n",
    "                                     y_lim_max = 60,\n",
    "                                     separate_plot = False):\n",
    "    \n",
    "    labels = updated_spike_infos['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 2\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    ghost_array = np.array(['NaN' for x in range(len(signal))])\n",
    "    ghost_array = ghost_array.astype(float)\n",
    "    spike_data_clusterized_oneline = []\n",
    "    legend = ['Signald\\'origine']\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        \n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == nb],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        legend.append('Cluster n°' + str(nb))\n",
    "\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == -1],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        legend.append('Cluster de bruit')\n",
    "    \n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    axes.plot(signal.index, signal.values)\n",
    "    axes.plot(signal.index, np.transpose(spike_data_clusterized_oneline))\n",
    "    axes.legend(legend)\n",
    "    axes.set_xlabel('Time in ms')\n",
    "    axes.set_title('Tous les clusters')\n",
    "    axes.set_ylim(y_lim_min , y_lim_max)\n",
    "    axes.grid()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#print_spikes_clusterized_oneline_total(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Amplitudes and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme de différences d'amplitude Peak-to-Peak des spikes\n",
    "\n",
    "def histogram_spikes_amplitude(spike_info):\n",
    "    plt.hist(spike_info['Delta_amplitudes'], bins='auto')\n",
    "    plt.title(\"Histogram of Spike Peak-to-Peak Amplitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme de l'écartement temporel des spikes (imax-imin)\n",
    "\n",
    "def histogram_spikes_time(spike_info):\n",
    "    plt.hist(spike_info['i_max-i_min'], bins='auto')\n",
    "    plt.title(\"Histogram of Spike i_max-i_min\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme des différences d'amplitude Peak-to-Peak des spikes:\n",
    "\n",
    "## ¡¡¡ATTENTION!!! Il faut que le spike info en entrée, soit mis à jour avec les labels des clusters\n",
    "\n",
    "def histogram_amplitude_clusterized(updated_spike_info):\n",
    "    \n",
    "    labels = updated_spike_info['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    for nb in range(nb_clusters):\n",
    "        local_info = spike_info.loc[spike_info['cluster_label'] == nb]\n",
    "        plt.figure()\n",
    "        plt.hist(local_info['cluster_label'], bins='auto')\n",
    "        plt.title(\"Histogram of Spike i_max-i_min of cluster n°\"+str(nb))\n",
    "        plt.show()\n",
    "    \n",
    "    if(-1 in labels) == True:\n",
    "        local_info = spike_info.loc[spike_info['cluster_label']==-1]\n",
    "        plt.figure()\n",
    "        plt.hist(local_info['cluster_label'], bins='auto')\n",
    "        plt.title(\"Histogram of Spike i_max-i_min of cluster of noise\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Function: PCA_and_AGGLOCLUST_spikes(spike_data, spike_info, nb_PCA_components=3,\n",
    "                                        #n_clusters=5,metric = 'euclidean',linkage='ward')\n",
    "\n",
    "PCA_X, aggloclustering, updated_spike_info = PCA_and_AGGLOCLUST_spikes(spike_data,\n",
    "                                                                       spike_info, nb_PCA_components=3,\n",
    "                                                                       n_clusters=5, metric=\"euclidean\", \n",
    "                                                                       linkage=\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggloclustering.labels_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: PCA_plot(spike_data, nb_clusters=3)\n",
    "\n",
    "PCA_plot(PCA_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_clusters_3d(labels, PCA_X)\n",
    "\n",
    "print_clusters_3d(aggloclustering.labels_, PCA_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized(spike_data,\n",
    "#                             labels,\n",
    "#                             t_before_alignement = 0.0015,\n",
    "#                             nb_spike = 20,\n",
    "#                             y_lim_min = -50,\n",
    "#                             y_lim_max = 60,\n",
    "#                             fs = 25000)\n",
    "                        \n",
    "print_spikes_clusterized(spike_data,\n",
    "                             aggloclustering.labels_,\n",
    "                             t_before_alignement = time_before,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = -50,\n",
    "                             y_lim_max = 60,\n",
    "                             fs = fs)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:1705: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  return self.func(*args)\n"
     ]
    }
   ],
   "source": [
    "# Function: print_spikes_clusterized_oneline(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline(signal,\n",
    "                                 updated_spike_info,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:1705: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  return self.func(*args)\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n"
     ]
    }
   ],
   "source": [
    "# Function: print_spikes_clusterized_oneline_total(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline_total(signal,\n",
    "                                 updated_spike_info,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: histogram_spikes_amplitude(spike_info)\n",
    "\n",
    "histogram_spikes_amplitude(spike_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:1705: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  return self.func(*args)\n"
     ]
    }
   ],
   "source": [
    "# Function: histogram_spikes_time(spike_info)\n",
    "\n",
    "histogram_spikes_time(spike_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: histogram_amplitude_clusterized(spike_info)\n",
    "\n",
    "histogram_amplitude_clusterized(updated_spike_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
