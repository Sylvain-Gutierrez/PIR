{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering\n",
    "\n",
    "### 01_06_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed for the tutorial\n",
    "\n",
    "# General syntax to import specific functions in a library: \n",
    "##from (library) import (specific library function)\n",
    "\n",
    "#from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "\n",
    "# General syntax to import a library but no functions: \n",
    "##import (library) as (give the library a nickname/alias)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "#import scipy.signal as signal\n",
    "from scipy.signal import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "#import sys  \n",
    "#sys.path.insert(0, '/Users/louiseplacidet/Desktop/PIR/GITPIR/GIT_29_04/PIR/AdabandFlt')\n",
    "#sys.path.insert(0, '/Users/SYL21/External_Drive/SUPAERO/PIR/AdabandFlt')\n",
    "#sys.path.insert(0, '/Users/louiseplacidet/Desktop/PIR/GITPIR/GIT_29_04/PIR/AdabandFlt')\n",
    "#from AdaBandFlt import *\n",
    "#from V2AdaBandFlt import *\n",
    "#from V3AdaBandFlt import *\n",
    "from AdaBandFlt_Burst_Distinction import *\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "# file path of csv file\n",
    "#Location = r'/Users/SYL21/External_Drive/SUPAERO/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/SYL21/External_Drive/SUPAERO/PIR/Data/Wetransfer_data/E18KABaseline_BcutV2groundAll.txt'\n",
    "Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_spike_data/newdata/E18KABaseline_BcutV2groundAll.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_new_spike_data/539W6cbaseRaw.txt'\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_data = 1000000\n",
    "fs = 25000\n",
    "\n",
    "method_align = 'indice_1er_depass'\n",
    "time_before = 0.0015\n",
    "time_after = 0.0015\n",
    "\n",
    "threshold_factor = 3.5\n",
    "maxseparation = 0.0008\n",
    "reduct_factor = 0.6\n",
    "burst_threshold = 6 #µV\n",
    "\n",
    "#n_electrode = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering functions and cutoff frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 100.0\n",
    "highcut = 2500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%t</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.307352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.544771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.605717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.378022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>-0.142189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.80</th>\n",
       "      <td>2.573249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.84</th>\n",
       "      <td>2.422268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.88</th>\n",
       "      <td>1.923271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.92</th>\n",
       "      <td>1.101855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.96</th>\n",
       "      <td>0.087807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "%t                     \n",
       "0.00           0.307352\n",
       "0.04           0.544771\n",
       "0.08           0.605717\n",
       "0.12           0.378022\n",
       "0.16          -0.142189\n",
       "...                 ...\n",
       "20799.80       2.573249\n",
       "20799.84       2.422268\n",
       "20799.88       1.923271\n",
       "20799.92       1.101855\n",
       "20799.96       0.087807\n",
       "\n",
       "[520000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_to_filter = df.iloc[:size_of_data,6] #Electrode 58\n",
    "\n",
    "y = butter_bandpass_filter(signal_to_filter, lowcut, highcut, fs, order=6)\n",
    "\n",
    "filtereddf = pd.DataFrame(y)\n",
    "filtereddf.index = df.index\n",
    "\n",
    "filtereddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_filtered = filtereddf.iloc[:,0]\n",
    "signal = filtereddf.iloc[:,0] ##selecting an electrode to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and Aligning the Spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Thresholds adapted to Noise Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = init_noise_levels(signal_filtered, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      estimator_type = \"RMS\",\n",
    "                      percentile_value = 25)\n",
    "\n",
    "#plt.figure()\n",
    "#plt.plot(noise_levels)\n",
    "#plt.grid(True)\n",
    "#plt.xlabel('Time')\n",
    "#plt.ylabel('Noise Amplitude [µV]')\n",
    "#plt.title('Noise Levels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spike_info = find_spikes(signal, noise_levels, fs,\n",
    "               window_size = 0.002,\n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = threshold_factor,\n",
    "               maxseparation = maxseparation,\n",
    "               time_checkmaxlocal = 0.0002,\n",
    "               burst_threshold = burst_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_fine_tuning(spike_info):\n",
    "    true_before = spike_info.loc[spike_info['burst?'] == True]\n",
    "    True_spikes = true_before.index.values\n",
    "    true_before.index = [x for x in range(len(true_before))]\n",
    "    for i in range(len(true_before)-1):\n",
    "        if(true_before.loc[i+1]['indice_1er_depass']-true_before.loc[i]['indice_1er_depass']<1000):\n",
    "            for j in range(True_spikes[i],True_spikes[i+1]):\n",
    "                spike_info.at[j, 'burst?'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indice_min</th>\n",
       "      <th>indice_1er_depass</th>\n",
       "      <th>indice_max_gauche</th>\n",
       "      <th>indice_max_droite</th>\n",
       "      <th>Delta_amplitudes</th>\n",
       "      <th>burst?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18570</td>\n",
       "      <td>18567</td>\n",
       "      <td>nan</td>\n",
       "      <td>18580</td>\n",
       "      <td>12.177648</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47134</td>\n",
       "      <td>47133</td>\n",
       "      <td>47117</td>\n",
       "      <td>nan</td>\n",
       "      <td>12.213912</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53735</td>\n",
       "      <td>53734</td>\n",
       "      <td>53723</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.627349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53994</td>\n",
       "      <td>53990</td>\n",
       "      <td>nan</td>\n",
       "      <td>54006</td>\n",
       "      <td>14.558499</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>54123</td>\n",
       "      <td>54117</td>\n",
       "      <td>nan</td>\n",
       "      <td>54136</td>\n",
       "      <td>12.651068</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>473956</td>\n",
       "      <td>473954</td>\n",
       "      <td>nan</td>\n",
       "      <td>473975</td>\n",
       "      <td>21.183660</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>474998</td>\n",
       "      <td>474996</td>\n",
       "      <td>474988</td>\n",
       "      <td>nan</td>\n",
       "      <td>13.975408</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>477110</td>\n",
       "      <td>477109</td>\n",
       "      <td>477091</td>\n",
       "      <td>nan</td>\n",
       "      <td>15.644971</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>506940</td>\n",
       "      <td>506938</td>\n",
       "      <td>nan</td>\n",
       "      <td>506949</td>\n",
       "      <td>14.447731</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>512732</td>\n",
       "      <td>512730</td>\n",
       "      <td>512725</td>\n",
       "      <td>512740</td>\n",
       "      <td>13.014314</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indice_min  indice_1er_depass indice_max_gauche indice_max_droite  \\\n",
       "2         18570              18567               nan             18580   \n",
       "8         47134              47133             47117               nan   \n",
       "10        53735              53734             53723               nan   \n",
       "11        53994              53990               nan             54006   \n",
       "12        54123              54117               nan             54136   \n",
       "..          ...                ...               ...               ...   \n",
       "202      473956             473954               nan            473975   \n",
       "206      474998             474996            474988               nan   \n",
       "207      477110             477109            477091               nan   \n",
       "212      506940             506938               nan            506949   \n",
       "213      512732             512730            512725            512740   \n",
       "\n",
       "     Delta_amplitudes  burst?  \n",
       "2           12.177648    True  \n",
       "8           12.213912    True  \n",
       "10          16.627349    True  \n",
       "11          14.558499    True  \n",
       "12          12.651068    True  \n",
       "..                ...     ...  \n",
       "202         21.183660    True  \n",
       "206         13.975408    True  \n",
       "207         15.644971    True  \n",
       "212         14.447731    True  \n",
       "213         13.014314    True  \n",
       "\n",
       "[161 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_fine_tuning(spike_info)\n",
    "spike_info.loc[spike_info['burst?'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spike_info.loc[spike_info['burst?'] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 77)\n"
     ]
    }
   ],
   "source": [
    "spike_data_burst = record_spikes(signal, fs, spike_info.loc[spike_info['burst?'] == True],\n",
    "                  method_align,\n",
    "                  t_before = time_before,\n",
    "                  t_after = time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 77)\n"
     ]
    }
   ],
   "source": [
    "spike_data_no_burst = record_spikes(signal, fs, spike_info.loc[spike_info['burst?'] == False],\n",
    "                  method_align,\n",
    "                  t_before = time_before,\n",
    "                  t_after = time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_oneline_burst = record_spikes_oneline(signal, fs, spike_info.loc[spike_info['burst?'] == True],\n",
    "                  method_align,\n",
    "                  t_before = time_before,\n",
    "                  t_after = time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_oneline_no_burst = record_spikes_oneline(signal, fs, spike_info.loc[spike_info['burst?'] == False],\n",
    "                  method_align,\n",
    "                  t_before = time_before,\n",
    "                  t_after = time_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:1705: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  return self.func(*args)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(df.index, signal, color = 'blue')\n",
    "plt.plot(spike_data_burst.index, spike_data_burst, color = 'red')\n",
    "plt.plot(spike_data_no_burst.index, spike_data_no_burst, color = 'purple')\n",
    "plt.title('Filtered Signal with Detected Spikes with RMS')\n",
    "plt.xlabel('Time Windows')\n",
    "plt.ylabel('Amplitude [µV]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spikes(spike_data_burst,\n",
    "             t_before_alignement = time_before,\n",
    "             first_spike = 1,\n",
    "             last_spike = 40,\n",
    "             fs = fs)\n",
    "\n",
    "print_spikes(spike_data_no_burst,\n",
    "             t_before_alignement = time_before,\n",
    "             first_spike = 1,\n",
    "             last_spike = 40,\n",
    "             fs = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilan PCA + AGGLOMERATIVE CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and AGGLOMERATIVE CLUSERING on spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_and_AGGLOCLUST_spikes(spike_data, spike_info, nb_PCA_components=3,\n",
    "                              n_clusters=5, metric='euclidean', linkage='ward'):\n",
    "    \n",
    "    ## on rééquilibre les valeurs dans les différentes dimensions\n",
    "    #pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    #pca_data = StandardScaler().fit_transform(pca_data) # normalizing the features\n",
    "    \n",
    "    ## PCA\n",
    "    pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    pca = PCA(n_components=nb_PCA_components)\n",
    "    pca.fit(pca_data)\n",
    "    PCA_X = pca.transform(pca_data)\n",
    "    \n",
    "    ## AGGLOMERATIVE CLUSTERING\n",
    "    ## Different linkages: 'ward', 'average', 'complete', 'single'\n",
    "    \n",
    "    aggloclustering = AgglomerativeClustering(n_clusters=n_clusters, affinity = metric,\n",
    "                                    linkage=linkage)\n",
    "    aggloclustering.fit(PCA_X)\n",
    "    \n",
    "    labels = aggloclustering.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    \n",
    "    ## Ajout du label des clusters dans spike info\n",
    "    spike_info['cluster_label'] = aggloclustering.labels_\n",
    "    \n",
    "    return PCA_X, aggloclustering, spike_info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering function info: \n",
    "AgglomerativeClustering(n_clusters=2, *, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward', distance_threshold=None)\n",
    "\n",
    "- affinity: “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”\n",
    "    NB: if linkage is ward: only \"euclidean\" is accepted\n",
    "- linkage{“ward”, “complete”, “average”, “single”}, default=”ward”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui plot la PCA\n",
    "\n",
    "def PCA_plot(PCA_X):\n",
    "    \n",
    "    fig = plt.figure(4,figsize=(4,3))\n",
    "    plt.clf()\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "    plt.cla()\n",
    "  \n",
    "    ax.scatter(PCA_X[:, 0], PCA_X[:, 1], PCA_X[:, 2], cmap=plt.cm.nipy_spectral,\n",
    "           edgecolor='k')\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the AGGLO CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui plot les clusters d'OPTICS\n",
    "\n",
    "def print_clusters_3d(labels, PCA_X):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    nb_clusters = max(labels) + 1\n",
    "\n",
    "    a = [i for i in range(len(labels))]\n",
    "    b = np.transpose([a,list(labels)])\n",
    "\n",
    "    for nb in range(nb_clusters):\n",
    "        legend = 'Cluster n°'+str(nb)\n",
    "        data = PCA_X[[x for x,y in b if y==nb],:]\n",
    "        ax.scatter(data[:,0], data[:,1], data[:,2],label=legend)\n",
    "    data = PCA_X[[x for x,y in b if y==-1],:]\n",
    "    ax.scatter(data[:,0], data[:,1], data[:,2], c='black',label='Noise cluster')    \n",
    "    \n",
    "    ax.set_title('Nombre de cluster(s) :' + str(nb_clusters))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#print_clusters_3d(kmeans.labels_, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the spikes from the different clusters after OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spikes_clusterized(spike_data,\n",
    "                             labels,\n",
    "                             t_before_alignement = 0,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = -50,\n",
    "                             y_lim_max = 60,\n",
    "                             fs = 25000):\n",
    "    \n",
    "    nb_clusters = max(labels) + 1\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    #spike_data.iloc[:,first_spike:last_spike].plot()\n",
    "    t_b = int(np.round(fs*(t_before_alignement)))\n",
    "    y = (spike_data.iloc[:,0]-t_b)*1000/fs\n",
    "        \n",
    "    a = [i+1 for i in range(len(labels))]\n",
    "    b = np.transpose([a,list(labels)])\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        data = spike_data.iloc[:,[x for x,y in b if y==nb]]\n",
    "        m = len(data.values[0])\n",
    "        nb_spikes_in_cluster = len(data.columns)\n",
    "\n",
    "        \n",
    "        kept = []\n",
    "        \n",
    "        if m <= nb_spike:\n",
    "            kept = [i for i in range(m)]\n",
    "        else:      \n",
    "            i = 0  \n",
    "            while i < nb_spike:\n",
    "                r = randint(0,m-1)\n",
    "                if (r in kept) == False:\n",
    "                    kept.append(r)\n",
    "                    i += 1\n",
    "        \n",
    "        x = data.iloc[:,kept].values\n",
    "        axes = figure.add_subplot(nb_line, 2, nb+1)\n",
    "        axes.plot(y, x)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster numero ' + str(nb))\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid(True)\n",
    "        axes.legend([str(nb_spikes_in_cluster)+' spikes'])\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        data = spike_data.iloc[:,[x for x,y in b if y==-1]]\n",
    "        m = len(data.values[0])\n",
    "        nb_spikes_in_cluster = len(data.columns)\n",
    "    \n",
    "        kept = []\n",
    "        \n",
    "        if m <= nb_spike:\n",
    "            kept = [i for i in range(m)]\n",
    "        else:      \n",
    "            i = 0  \n",
    "            while i < nb_spike:\n",
    "                r = randint(0,m-1)\n",
    "                if (r in kept) == False:\n",
    "                    kept.append(r)\n",
    "                    i += 1\n",
    "        \n",
    "        x = data.iloc[:,kept].values\n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "        axes.plot(y, x)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster de bruit')\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid(True)\n",
    "        axes.legend([str(nb_spikes_in_cluster)+' spikes'])\n",
    "        \n",
    "#print_spikes_clusterized(spike_data,\n",
    "#                             dbscan.labels_,\n",
    "#                             t_before_alignement = 0.0015,\n",
    "#                             nb_spike = 20,\n",
    "#                             y_lim_min = -50,\n",
    "#                             y_lim_max = 60,\n",
    "#                             fs = 25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the spikes from clusters on original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui affiche les spikes des différents clusters sur échelle temporelle\n",
    "\n",
    "def print_spikes_clusterized_oneline(signal,\n",
    "                                     updated_spike_infos,\n",
    "                                     align_method = 'indice_zero_central',\n",
    "                                     t_before = 0.001,\n",
    "                                     t_after = 0.002,\n",
    "                                     fs = 25000,\n",
    "                                     y_lim_min = -50,\n",
    "                                     y_lim_max = 60,\n",
    "                                     separate_plot = False):\n",
    "    \n",
    "    labels = updated_spike_infos['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 2\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    ghost_array = np.array(['NaN' for x in range(len(signal))])\n",
    "    ghost_array = ghost_array.astype(float)\n",
    "    spike_data_clusterized_oneline = []\n",
    "    legend = ['Signald\\'origine']\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        \n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == nb],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+1)\n",
    "        axes.plot(signal.index, signal.values)\n",
    "        for ghost in range(nb):\n",
    "            axes.plot(signal.index, ghost_array)\n",
    "        axes.plot(signal.index, spike_data_oneline)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster n°' + str(nb))\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid()\n",
    "        \n",
    "        legend.append('Cluster n°' + str(nb))\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == -1],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "        axes.plot(signal.index, signal.values)\n",
    "        axes.plot(signal.index, spike_data_oneline)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster de bruit')\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid()\n",
    "                \n",
    "        legend.append('Cluster de bruit')\n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+3)\n",
    "    else:\n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "    \n",
    "    axes.plot(signal.index, signal.values)\n",
    "    axes.plot(signal.index, np.transpose(spike_data_clusterized_oneline))\n",
    "    axes.legend(legend)\n",
    "    axes.set_xlabel('Time in ms')\n",
    "    axes.set_title('Tous les clusters')\n",
    "    axes.set_ylim(y_lim_min , y_lim_max)\n",
    "    axes.grid()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#print_spikes_clusterized_oneline(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui affiche les spikes des différents clusters sur échelle temporelle\n",
    "\n",
    "def print_spikes_clusterized_oneline_total(signal,\n",
    "                                     updated_spike_infos,\n",
    "                                     align_method = 'indice_zero_central',\n",
    "                                     t_before = 0.001,\n",
    "                                     t_after = 0.002,\n",
    "                                     fs = 25000,\n",
    "                                     y_lim_min = -50,\n",
    "                                     y_lim_max = 60,\n",
    "                                     separate_plot = False):\n",
    "    \n",
    "    labels = updated_spike_infos['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 2\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    ghost_array = np.array(['NaN' for x in range(len(signal))])\n",
    "    ghost_array = ghost_array.astype(float)\n",
    "    spike_data_clusterized_oneline = []\n",
    "    legend = ['Signald\\'origine']\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        \n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == nb],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        legend.append('Cluster n°' + str(nb))\n",
    "\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == -1],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        legend.append('Cluster de bruit')\n",
    "    \n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    axes.plot(signal.index, signal.values)\n",
    "    axes.plot(signal.index, np.transpose(spike_data_clusterized_oneline))\n",
    "    axes.legend(legend)\n",
    "    axes.set_xlabel('Time in ms')\n",
    "    axes.set_title('Tous les clusters')\n",
    "    axes.set_ylim(y_lim_min , y_lim_max)\n",
    "    axes.grid()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#print_spikes_clusterized_oneline_total(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Amplitudes and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme de différences d'amplitude Peak-to-Peak des spikes\n",
    "\n",
    "def histogram_spikes_amplitude(spike_info):\n",
    "    plt.hist(spike_info['Delta_amplitudes'], bins='auto')\n",
    "    plt.title(\"Histogram of Spike Peak-to-Peak Amplitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme de l'écartement temporel des spikes (imax-imin)\n",
    "\n",
    "def histogram_spikes_time(spike_info):\n",
    "    plt.hist(spike_info['i_max-i_min'], bins='auto')\n",
    "    plt.title(\"Histogram of Spike i_max-i_min\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme des différences d'amplitude Peak-to-Peak des spikes:\n",
    "\n",
    "## ¡¡¡ATTENTION!!! Il faut que le spike info en entrée, soit mis à jour avec les labels des clusters\n",
    "\n",
    "def histogram_amplitude_clusterized(updated_spike_info):\n",
    "    \n",
    "    labels = updated_spike_info['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    for nb in range(nb_clusters):\n",
    "        local_info = spike_info.loc[spike_info['cluster_label'] == nb]\n",
    "        plt.figure()\n",
    "        plt.hist(local_info['cluster_label'], bins='auto')\n",
    "        plt.title(\"Histogram of Spike i_max-i_min of cluster n°\"+str(nb))\n",
    "        plt.show()\n",
    "    \n",
    "    if(-1 in labels) == True:\n",
    "        local_info = spike_info.loc[spike_info['cluster_label']==-1]\n",
    "        plt.figure()\n",
    "        plt.hist(local_info['cluster_label'], bins='auto')\n",
    "        plt.title(\"Histogram of Spike i_max-i_min of cluster of noise\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Function: PCA_and_AGGLOCLUST_spikes(spike_data, spike_info, nb_PCA_components=3,\n",
    "                                        #n_clusters=5,metric = 'euclidean',linkage='ward')\n",
    "\n",
    "PCA_X, aggloclustering, updated_spike_info = PCA_and_AGGLOCLUST_spikes(spike_data,\n",
    "                                                                       spike_info, nb_PCA_components=3,\n",
    "                                                                       n_clusters=5, metric=\"euclidean\", \n",
    "                                                                       linkage=\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggloclustering.labels_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: PCA_plot(spike_data, nb_clusters=3)\n",
    "\n",
    "PCA_plot(PCA_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_clusters_3d(labels, PCA_X)\n",
    "\n",
    "print_clusters_3d(aggloclustering.labels_, PCA_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized(spike_data,\n",
    "#                             labels,\n",
    "#                             t_before_alignement = 0.0015,\n",
    "#                             nb_spike = 20,\n",
    "#                             y_lim_min = -50,\n",
    "#                             y_lim_max = 60,\n",
    "#                             fs = 25000)\n",
    "                        \n",
    "print_spikes_clusterized(spike_data,\n",
    "                             aggloclustering.labels_,\n",
    "                             t_before_alignement = time_before,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = -50,\n",
    "                             y_lim_max = 60,\n",
    "                             fs = fs)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized_oneline(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline(signal,\n",
    "                                 updated_spike_info,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized_oneline_total(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline_total(signal,\n",
    "                                 updated_spike_info,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: histogram_spikes_amplitude(spike_info)\n",
    "\n",
    "histogram_spikes_amplitude(spike_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: histogram_spikes_time(spike_info)\n",
    "\n",
    "histogram_spikes_time(spike_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: histogram_amplitude_clusterized(spike_info)\n",
    "\n",
    "histogram_amplitude_clusterized(updated_spike_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
