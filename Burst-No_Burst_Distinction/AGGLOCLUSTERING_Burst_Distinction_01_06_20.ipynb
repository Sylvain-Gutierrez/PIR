{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering\n",
    "\n",
    "### 01_06_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed for the tutorial\n",
    "\n",
    "# General syntax to import specific functions in a library: \n",
    "##from (library) import (specific library function)\n",
    "\n",
    "#from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "\n",
    "# General syntax to import a library but no functions: \n",
    "##import (library) as (give the library a nickname/alias)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "#import scipy.signal as signal\n",
    "from scipy.signal import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "#import sys  \n",
    "#sys.path.insert(0, '/Users/louiseplacidet/Desktop/PIR/GITPIR/GIT_29_04/PIR/AdabandFlt')\n",
    "#sys.path.insert(0, '/Users/SYL21/External_Drive/SUPAERO/PIR/AdabandFlt')\n",
    "#sys.path.insert(0, '/Users/louiseplacidet/Desktop/PIR/GITPIR/GIT_29_04/PIR/AdabandFlt')\n",
    "#from AdaBandFlt import *\n",
    "#from V2AdaBandFlt import *\n",
    "#from V3AdaBandFlt import *\n",
    "from AdaBandFlt_Burst_Distinction import *\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "# file path of csv file\n",
    "#Location = r'/Users/SYL21/External_Drive/SUPAERO/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/data_spikes/E18KABaseline_Bcut.txt'\n",
    "#Location = r'/Users/SYL21/External_Drive/SUPAERO/PIR/Data/Wetransfer_data/E18KABaseline_BcutV2groundAll.txt'\n",
    "Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_spike_data/newdata/E18KABaseline_BcutV2groundAll.txt'\n",
    "#Location = r'/Users/louiseplacidet/Desktop/PIR/Data/new_new_spike_data/539W6cbaseRaw.txt'\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv(Location, sep='\\t',skiprows=[0,1,3] , index_col='%t           ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_data = 1000000\n",
    "fs = 25000\n",
    "\n",
    "method_align = 'indice_1er_depass'\n",
    "time_before = 0.0015\n",
    "time_after = 0.0015\n",
    "\n",
    "threshold_factor = 3.2\n",
    "maxseparation = 0.001\n",
    "reduct_factor = 0.6\n",
    "burst_threshold = 7 #µV\n",
    "\n",
    "#n_electrode = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering functions and cutoff frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 100.0\n",
    "highcut = 2500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%t</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.307352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.544771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.605717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.378022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>-0.142189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.80</th>\n",
       "      <td>2.573249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.84</th>\n",
       "      <td>2.422268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.88</th>\n",
       "      <td>1.923271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.92</th>\n",
       "      <td>1.101855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799.96</th>\n",
       "      <td>0.087807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "%t                     \n",
       "0.00           0.307352\n",
       "0.04           0.544771\n",
       "0.08           0.605717\n",
       "0.12           0.378022\n",
       "0.16          -0.142189\n",
       "...                 ...\n",
       "20799.80       2.573249\n",
       "20799.84       2.422268\n",
       "20799.88       1.923271\n",
       "20799.92       1.101855\n",
       "20799.96       0.087807\n",
       "\n",
       "[520000 rows x 1 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_to_filter = df.iloc[:size_of_data,6] #Electrode 58\n",
    "\n",
    "y = butter_bandpass_filter(signal_to_filter, lowcut, highcut, fs, order=6)\n",
    "\n",
    "filtereddf = pd.DataFrame(y)\n",
    "filtereddf.index = df.index\n",
    "\n",
    "filtereddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_filtered = filtereddf.iloc[:,0]\n",
    "signal = filtereddf.iloc[:,0] ##selecting an electrode to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and Aligning the Spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Thresholds adapted to Noise Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = init_noise_levels(signal_filtered, fs, \n",
    "                      noise_window_size = 0.01,\n",
    "                      required_valid_windows = 100,\n",
    "                      old_noise_level_propagation = 0.8, \n",
    "                      test_level = 5,\n",
    "                      estimator_type = \"RMS\",\n",
    "                      percentile_value = 25)\n",
    "\n",
    "#plt.figure()\n",
    "#plt.plot(noise_levels)\n",
    "#plt.grid(True)\n",
    "#plt.xlabel('Time')\n",
    "#plt.ylabel('Noise Amplitude [µV]')\n",
    "#plt.title('Noise Levels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spike_info = find_spikes(signal, noise_levels, fs,\n",
    "               window_size = 0.002,\n",
    "               noise_window_size = 0.01,\n",
    "               threshold_factor = threshold_factor,\n",
    "               maxseparation = maxseparation,\n",
    "               time_checkmaxlocal = 0.0002,\n",
    "               burst_threshold = burst_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_fine_tuning(spike_info):\n",
    "    true_before = spike_info.loc[spike_info['burst?'] == True]\n",
    "    True_spikes = true_before.index.values\n",
    "    true_before.index = [x for x in range(len(true_before))]\n",
    "    for i in range(len(true_before)-1):\n",
    "        if(true_before.loc[i+1]['indice_1er_depass']-true_before.loc[i]['indice_1er_depass']<5000):\n",
    "            for j in range(True_spikes[i],True_spikes[i+1]):\n",
    "                spike_info.at[j, 'burst?'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indice_min</th>\n",
       "      <th>indice_1er_depass</th>\n",
       "      <th>indice_max_gauche</th>\n",
       "      <th>indice_max_droite</th>\n",
       "      <th>Delta_amplitudes</th>\n",
       "      <th>burst?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53735</td>\n",
       "      <td>53734</td>\n",
       "      <td>53723</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.627349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53813</td>\n",
       "      <td>53812</td>\n",
       "      <td>53797</td>\n",
       "      <td>nan</td>\n",
       "      <td>9.744262</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>53877</td>\n",
       "      <td>53876</td>\n",
       "      <td>53854</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.149789</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>53994</td>\n",
       "      <td>53989</td>\n",
       "      <td>nan</td>\n",
       "      <td>54006</td>\n",
       "      <td>14.558499</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54153</td>\n",
       "      <td>54150</td>\n",
       "      <td>54136</td>\n",
       "      <td>54161</td>\n",
       "      <td>13.409454</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>474865</td>\n",
       "      <td>474864</td>\n",
       "      <td>474847</td>\n",
       "      <td>nan</td>\n",
       "      <td>9.991345</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>474998</td>\n",
       "      <td>474996</td>\n",
       "      <td>474988</td>\n",
       "      <td>475020</td>\n",
       "      <td>13.975408</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>475440</td>\n",
       "      <td>475439</td>\n",
       "      <td>475424</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.654518</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>477110</td>\n",
       "      <td>477109</td>\n",
       "      <td>477091</td>\n",
       "      <td>nan</td>\n",
       "      <td>15.644971</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>506940</td>\n",
       "      <td>506938</td>\n",
       "      <td>nan</td>\n",
       "      <td>506949</td>\n",
       "      <td>14.447731</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indice_min  indice_1er_depass indice_max_gauche indice_max_droite  \\\n",
       "18        53735              53734             53723               nan   \n",
       "19        53813              53812             53797               nan   \n",
       "20        53877              53876             53854               nan   \n",
       "21        53994              53989               nan             54006   \n",
       "22        54153              54150             54136             54161   \n",
       "..          ...                ...               ...               ...   \n",
       "356      474865             474864            474847               nan   \n",
       "357      474998             474996            474988            475020   \n",
       "358      475440             475439            475424               nan   \n",
       "359      477110             477109            477091               nan   \n",
       "372      506940             506938               nan            506949   \n",
       "\n",
       "     Delta_amplitudes  burst?  \n",
       "18          16.627349    True  \n",
       "19           9.744262    True  \n",
       "20          16.149789    True  \n",
       "21          14.558499    True  \n",
       "22          13.409454    True  \n",
       "..                ...     ...  \n",
       "356          9.991345    True  \n",
       "357         13.975408    True  \n",
       "358         10.654518    True  \n",
       "359         15.644971    True  \n",
       "372         14.447731    True  \n",
       "\n",
       "[210 rows x 6 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_fine_tuning(spike_info)\n",
    "spike_info.loc[spike_info['burst?'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spike_info.loc[spike_info['burst?'] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 77)\n"
     ]
    }
   ],
   "source": [
    "spike_data_burst = record_spikes(signal, fs, spike_info.loc[spike_info['burst?'] == True],\n",
    "                  method_align,\n",
    "                  t_before = time_before,\n",
    "                  t_after = time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 77)\n"
     ]
    }
   ],
   "source": [
    "spike_data_no_burst = record_spikes(signal, fs, spike_info.loc[spike_info['burst?'] == False],\n",
    "                  method_align,\n",
    "                  t_before = time_before,\n",
    "                  t_after = time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_oneline_burst = record_spikes_oneline(signal, fs, spike_info.loc[spike_info['burst?'] == True],\n",
    "                  method_align,\n",
    "                  t_before = time_before,\n",
    "                  t_after = time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data_oneline_no_burst = record_spikes_oneline(signal, fs, spike_info.loc[spike_info['burst?'] == False],\n",
    "                  method_align,\n",
    "                  t_before = time_before,\n",
    "                  t_after = time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_info_burst = spike_info.loc[spike_info['burst?'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_info_no_burst = spike_info.loc[spike_info['burst?'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.index, signal, color = 'blue')\n",
    "plt.plot(spike_data_oneline_burst.index, spike_data_oneline_burst, color = 'red',label='from burst')\n",
    "plt.plot(spike_data_oneline_no_burst.index, spike_data_oneline_no_burst, color = 'purple',label='not from burst')\n",
    "plt.title('Filtered Signal with Detected Spikes with RMS')\n",
    "plt.xlabel('Time Windows')\n",
    "plt.ylabel('Amplitude [µV]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Spikes not from burst')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_spikes(spike_data_burst,\n",
    "             t_before_alignement = time_before,\n",
    "             first_spike = 1,\n",
    "             last_spike = 40,\n",
    "             fs = fs)\n",
    "plt.title(\"Spikes from burst\")\n",
    "\n",
    "print_spikes(spike_data_no_burst,\n",
    "             t_before_alignement = time_before,\n",
    "             first_spike = 1,\n",
    "             last_spike = 40,\n",
    "             fs = fs)\n",
    "plt.title(\"Spikes not from burst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilan PCA + AGGLOMERATIVE CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and AGGLOMERATIVE CLUSERING on spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_and_AGGLOCLUST_spikes(spike_data, spike_info, nb_PCA_components=3,\n",
    "                              n_clusters=5, metric='euclidean', linkage='ward'):\n",
    "    \n",
    "    ## on rééquilibre les valeurs dans les différentes dimensions\n",
    "    #pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    #pca_data = StandardScaler().fit_transform(pca_data) # normalizing the features\n",
    "    \n",
    "    ## PCA\n",
    "    pca_data = np.array(spike_data.iloc[:,1:].values).transpose()\n",
    "    pca = PCA(n_components=nb_PCA_components)\n",
    "    pca.fit(pca_data)\n",
    "    PCA_X = pca.transform(pca_data)\n",
    "    \n",
    "    ## AGGLOMERATIVE CLUSTERING\n",
    "    ## Different linkages: 'ward', 'average', 'complete', 'single'\n",
    "    \n",
    "    aggloclustering = AgglomerativeClustering(n_clusters=n_clusters, affinity = metric,\n",
    "                                    linkage=linkage)\n",
    "    aggloclustering.fit(PCA_X)\n",
    "    \n",
    "    labels = aggloclustering.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    \n",
    "    ## Ajout du label des clusters dans spike info\n",
    "    spike_info['cluster_label'] = aggloclustering.labels_\n",
    "    \n",
    "    return PCA_X, aggloclustering, spike_info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering function info: \n",
    "AgglomerativeClustering(n_clusters=2, *, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward', distance_threshold=None)\n",
    "\n",
    "- affinity: “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”\n",
    "    NB: if linkage is ward: only \"euclidean\" is accepted\n",
    "- linkage{“ward”, “complete”, “average”, “single”}, default=”ward”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui plot la PCA\n",
    "\n",
    "def PCA_plot(PCA_X):\n",
    "    \n",
    "    fig = plt.figure(4,figsize=(4,3))\n",
    "    plt.clf()\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "    plt.cla()\n",
    "  \n",
    "    ax.scatter(PCA_X[:, 0], PCA_X[:, 1], PCA_X[:, 2], cmap=plt.cm.nipy_spectral,\n",
    "           edgecolor='k')\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the AGGLO CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui plot les clusters d'OPTICS\n",
    "\n",
    "def print_clusters_3d(labels, PCA_X):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    nb_clusters = max(labels) + 1\n",
    "\n",
    "    a = [i for i in range(len(labels))]\n",
    "    b = np.transpose([a,list(labels)])\n",
    "\n",
    "    for nb in range(nb_clusters):\n",
    "        legend = 'Cluster n°'+str(nb)\n",
    "        data = PCA_X[[x for x,y in b if y==nb],:]\n",
    "        ax.scatter(data[:,0], data[:,1], data[:,2],label=legend)\n",
    "    data = PCA_X[[x for x,y in b if y==-1],:]\n",
    "    ax.scatter(data[:,0], data[:,1], data[:,2], c='black',label='Noise cluster')    \n",
    "    \n",
    "    ax.set_title('Nombre de cluster(s) :' + str(nb_clusters))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#print_clusters_3d(kmeans.labels_, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the spikes from the different clusters after OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spikes_clusterized(spike_data,\n",
    "                             labels,\n",
    "                             t_before_alignement = 0,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = -50,\n",
    "                             y_lim_max = 60,\n",
    "                             fs = 25000):\n",
    "    \n",
    "    nb_clusters = max(labels) + 1\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    #spike_data.iloc[:,first_spike:last_spike].plot()\n",
    "    t_b = int(np.round(fs*(t_before_alignement)))\n",
    "    y = (spike_data.iloc[:,0]-t_b)*1000/fs\n",
    "        \n",
    "    a = [i+1 for i in range(len(labels))]\n",
    "    b = np.transpose([a,list(labels)])\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        data = spike_data.iloc[:,[x for x,y in b if y==nb]]\n",
    "        m = len(data.values[0])\n",
    "        nb_spikes_in_cluster = len(data.columns)\n",
    "\n",
    "        \n",
    "        kept = []\n",
    "        \n",
    "        if m <= nb_spike:\n",
    "            kept = [i for i in range(m)]\n",
    "        else:      \n",
    "            i = 0  \n",
    "            while i < nb_spike:\n",
    "                r = randint(0,m-1)\n",
    "                if (r in kept) == False:\n",
    "                    kept.append(r)\n",
    "                    i += 1\n",
    "        \n",
    "        x = data.iloc[:,kept].values\n",
    "        axes = figure.add_subplot(nb_line, 2, nb+1)\n",
    "        axes.plot(y, x)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster numero ' + str(nb))\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid(True)\n",
    "        axes.legend([str(nb_spikes_in_cluster)+' spikes'])\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        data = spike_data.iloc[:,[x for x,y in b if y==-1]]\n",
    "        m = len(data.values[0])\n",
    "        nb_spikes_in_cluster = len(data.columns)\n",
    "    \n",
    "        kept = []\n",
    "        \n",
    "        if m <= nb_spike:\n",
    "            kept = [i for i in range(m)]\n",
    "        else:      \n",
    "            i = 0  \n",
    "            while i < nb_spike:\n",
    "                r = randint(0,m-1)\n",
    "                if (r in kept) == False:\n",
    "                    kept.append(r)\n",
    "                    i += 1\n",
    "        \n",
    "        x = data.iloc[:,kept].values\n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "        axes.plot(y, x)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster de bruit')\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid(True)\n",
    "        axes.legend([str(nb_spikes_in_cluster)+' spikes'])\n",
    "        \n",
    "#print_spikes_clusterized(spike_data,\n",
    "#                             dbscan.labels_,\n",
    "#                             t_before_alignement = 0.0015,\n",
    "#                             nb_spike = 20,\n",
    "#                             y_lim_min = -50,\n",
    "#                             y_lim_max = 60,\n",
    "#                             fs = 25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the spikes from clusters on original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui affiche les spikes des différents clusters sur échelle temporelle\n",
    "\n",
    "def print_spikes_clusterized_oneline(signal,\n",
    "                                     updated_spike_infos,\n",
    "                                     align_method = 'indice_zero_central',\n",
    "                                     t_before = 0.001,\n",
    "                                     t_after = 0.002,\n",
    "                                     fs = 25000,\n",
    "                                     y_lim_min = -50,\n",
    "                                     y_lim_max = 60,\n",
    "                                     separate_plot = False):\n",
    "    \n",
    "    labels = updated_spike_infos['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 2\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    ghost_array = np.array(['NaN' for x in range(len(signal))])\n",
    "    ghost_array = ghost_array.astype(float)\n",
    "    spike_data_clusterized_oneline = []\n",
    "    legend = ['Signald\\'origine']\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        \n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == nb],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+1)\n",
    "        axes.plot(signal.index, signal.values)\n",
    "        for ghost in range(nb):\n",
    "            axes.plot(signal.index, ghost_array)\n",
    "        axes.plot(signal.index, spike_data_oneline)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster n°' + str(nb))\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid()\n",
    "        \n",
    "        legend.append('Cluster n°' + str(nb))\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == -1],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "        axes.plot(signal.index, signal.values)\n",
    "        axes.plot(signal.index, spike_data_oneline)\n",
    "        axes.set_xlabel('Time in ms')\n",
    "        axes.set_title('Cluster de bruit')\n",
    "        axes.set_ylim(y_lim_min , y_lim_max)\n",
    "        axes.grid()\n",
    "                \n",
    "        legend.append('Cluster de bruit')\n",
    "        \n",
    "        axes = figure.add_subplot(nb_line, 2, nb+3)\n",
    "    else:\n",
    "        axes = figure.add_subplot(nb_line, 2, nb+2)\n",
    "    \n",
    "    axes.plot(signal.index, signal.values)\n",
    "    axes.plot(signal.index, np.transpose(spike_data_clusterized_oneline))\n",
    "    axes.legend(legend)\n",
    "    axes.set_xlabel('Time in ms')\n",
    "    axes.set_title('Tous les clusters')\n",
    "    axes.set_ylim(y_lim_min , y_lim_max)\n",
    "    axes.grid()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#print_spikes_clusterized_oneline(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:1705: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  return self.func(*args)\n"
     ]
    }
   ],
   "source": [
    "## Fonction qui affiche les spikes des différents clusters sur échelle temporelle\n",
    "\n",
    "def print_spikes_clusterized_oneline_total(signal,\n",
    "                                     updated_spike_infos,\n",
    "                                     align_method = 'indice_zero_central',\n",
    "                                     t_before = 0.001,\n",
    "                                     t_after = 0.002,\n",
    "                                     fs = 25000,\n",
    "                                     y_lim_min = -50,\n",
    "                                     y_lim_max = 60,\n",
    "                                     separate_plot = False):\n",
    "    \n",
    "    labels = updated_spike_infos['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    if (-1 in labels) == True:\n",
    "        nb_clusters_ = nb_clusters + 2\n",
    "    else:\n",
    "        nb_clusters_ = nb_clusters + 1\n",
    "    \n",
    "    nb_line = nb_clusters_//2\n",
    "    if nb_clusters_%2 != 0:\n",
    "        nb_line += 1\n",
    "    \n",
    "    ghost_array = np.array(['NaN' for x in range(len(signal))])\n",
    "    ghost_array = ghost_array.astype(float)\n",
    "    spike_data_clusterized_oneline = []\n",
    "    legend = ['Signald\\'origine']\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    plt.gcf().subplots_adjust(left = 0.1, bottom = 0.1, right = 0.9, top = 0.9, wspace = 0.2, hspace = 0.5)\n",
    "    for nb in range(nb_clusters):\n",
    "        \n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == nb],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        \n",
    "        legend.append('Cluster n°' + str(nb))\n",
    "\n",
    "        \n",
    "    if (-1 in labels) == True:\n",
    "        spike_data_oneline = record_spikes_oneline(signal,\n",
    "                              fs,\n",
    "                              updated_spike_infos.loc[updated_spike_infos['cluster_label'] == -1],\n",
    "                              align_method,\n",
    "                              t_before = t_before,\n",
    "                              t_after = t_after)\n",
    "        spike_data_oneline = np.resize(spike_data_oneline.values,len(spike_data_oneline.values))\n",
    "        spike_data_clusterized_oneline.append(spike_data_oneline)\n",
    "        legend.append('Cluster de bruit')\n",
    "    \n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    axes.plot(signal.index, signal.values)\n",
    "    axes.plot(signal.index, np.transpose(spike_data_clusterized_oneline))\n",
    "    axes.legend(legend)\n",
    "    axes.set_xlabel('Time in ms')\n",
    "    axes.set_title('Tous les clusters')\n",
    "    axes.set_ylim(y_lim_min , y_lim_max)\n",
    "    axes.grid()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#print_spikes_clusterized_oneline_total(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Amplitudes and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme de différences d'amplitude Peak-to-Peak des spikes\n",
    "\n",
    "def histogram_spikes_amplitude(spike_info):\n",
    "    plt.hist(spike_info['Delta_amplitudes'], bins='auto')\n",
    "    plt.title(\"Histogram of Spike Peak-to-Peak Amplitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme de l'écartement temporel des spikes (imax-imin)\n",
    "\n",
    "def histogram_spikes_time(spike_info):\n",
    "    plt.hist(spike_info['i_max-i_min'], bins='auto')\n",
    "    plt.title(\"Histogram of Spike i_max-i_min\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histogramme des différences d'amplitude Peak-to-Peak des spikes:\n",
    "\n",
    "## ¡¡¡ATTENTION!!! Il faut que le spike info en entrée, soit mis à jour avec les labels des clusters\n",
    "\n",
    "def histogram_amplitude_clusterized(updated_spike_info):\n",
    "    \n",
    "    labels = updated_spike_info['cluster_label'].values\n",
    "    nb_clusters = max(labels) + 1\n",
    "    \n",
    "    for nb in range(nb_clusters):\n",
    "        local_info = spike_info.loc[spike_info['cluster_label'] == nb]\n",
    "        plt.figure()\n",
    "        plt.hist(local_info['cluster_label'], bins='auto')\n",
    "        plt.title(\"Histogram of Spike i_max-i_min of cluster n°\"+str(nb))\n",
    "        plt.show()\n",
    "    \n",
    "    if(-1 in labels) == True:\n",
    "        local_info = spike_info.loc[spike_info['cluster_label']==-1]\n",
    "        plt.figure()\n",
    "        plt.hist(local_info['cluster_label'], bins='auto')\n",
    "        plt.title(\"Histogram of Spike i_max-i_min of cluster of noise\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## Function: PCA_and_AGGLOCLUST_spikes(spike_data, spike_info, nb_PCA_components=3,\n",
    "                                        #n_clusters=5,metric = 'euclidean',linkage='ward')\n",
    "\n",
    "PCA_X_burst, aggloclustering_burst, updated_spike_info_burst = PCA_and_AGGLOCLUST_spikes(spike_data_burst,\n",
    "                                                                       spike_info_burst, nb_PCA_components=3,\n",
    "                                                                       n_clusters=5, metric=\"euclidean\", \n",
    "                                                                       linkage=\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "PCA_X_no_burst, aggloclustering_no_burst, updated_spike_info_no_burst = PCA_and_AGGLOCLUST_spikes(spike_data_no_burst,\n",
    "                                                                       spike_info_no_burst, nb_PCA_components=3,\n",
    "                                                                       n_clusters=5, metric=\"euclidean\", \n",
    "                                                                       linkage=\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aggloclustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-0d9ff6c7242d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maggloclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aggloclustering' is not defined"
     ]
    }
   ],
   "source": [
    "aggloclustering.labels_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.92, 'PCA with spikes in burst')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n"
     ]
    }
   ],
   "source": [
    "# Function: PCA_plot(spike_data, nb_clusters=3)\n",
    "PCA_plot(PCA_X_burst)\n",
    "plt.title(\"PCA with spikes in burst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.92, 'PCA with spikes not in burst')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_plot(PCA_X_no_burst)\n",
    "plt.title(\"PCA with spikes not in burst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_clusters_3d(labels, PCA_X)\n",
    "\n",
    "print_clusters_3d(aggloclustering_burst.labels_, PCA_X_burst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_clusters_3d(labels, PCA_X)\n",
    "\n",
    "print_clusters_3d(aggloclustering_no_burst.labels_, PCA_X_no_burst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized(spike_data,\n",
    "#                             labels,\n",
    "#                             t_before_alignement = 0.0015,\n",
    "#                             nb_spike = 20,\n",
    "#                             y_lim_min = -50,\n",
    "#                             y_lim_max = 60,\n",
    "#                             fs = 25000)\n",
    "                        \n",
    "print_spikes_clusterized(spike_data_burst,\n",
    "                             aggloclustering_burst.labels_,\n",
    "                             t_before_alignement = time_before,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = -20,\n",
    "                             y_lim_max = 20,\n",
    "                             fs = fs)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n"
     ]
    }
   ],
   "source": [
    "# Function: print_spikes_clusterized(spike_data,\n",
    "#                             labels,\n",
    "#                             t_before_alignement = 0.0015,\n",
    "#                             nb_spike = 20,\n",
    "#                             y_lim_min = -50,\n",
    "#                             y_lim_max = 60,\n",
    "#                             fs = 25000)\n",
    "                        \n",
    "print_spikes_clusterized(spike_data_no_burst,\n",
    "                             aggloclustering_no_burst.labels_,\n",
    "                             t_before_alignement = time_before,\n",
    "                             nb_spike = 20,\n",
    "                             y_lim_min = -10,\n",
    "                             y_lim_max = 10,\n",
    "                             fs = fs)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized_oneline(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline(signal,\n",
    "                                 updated_spike_info_burst,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized_oneline(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline(signal,\n",
    "                                 updated_spike_info_no_burst,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized_oneline_total(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline_total(signal,\n",
    "                                 updated_spike_info_burst,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: print_spikes_clusterized_oneline_total(signal,\n",
    "#                                 updated_spike_infos,\n",
    "#                                 align_method = 'indice_zero_central',\n",
    "#                                 t_before = 0.001,\n",
    "#                                 t_after = 0.002,\n",
    "#                                 fs = 25000,)\n",
    "\n",
    "print_spikes_clusterized_oneline_total(signal,\n",
    "                                 updated_spike_info_no_burst,\n",
    "                                 align_method = method_align,\n",
    "                                 t_before = time_before,\n",
    "                                 t_after = time_after,\n",
    "                                 fs = fs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: histogram_spikes_amplitude(spike_info)\n",
    "\n",
    "histogram_spikes_amplitude(spike_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: histogram_spikes_amplitude(spike_info)\n",
    "\n",
    "histogram_spikes_amplitude(spike_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'i_max-i_min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'i_max-i_min'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-ed931cea391c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function: histogram_spikes_time(spike_info)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistogram_spikes_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-141-c02ff7880388>\u001b[0m in \u001b[0;36mhistogram_spikes_time\u001b[0;34m(spike_info)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhistogram_spikes_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i_max-i_min'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Histogram of Spike i_max-i_min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'i_max-i_min'"
     ]
    }
   ],
   "source": [
    "# Function: histogram_spikes_time(spike_info)\n",
    "\n",
    "histogram_spikes_time(spike_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:749: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args)\n",
      "/opt/anaconda3/lib/python3.7/tkinter/__init__.py:1705: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  return self.func(*args)\n"
     ]
    }
   ],
   "source": [
    "# Function: histogram_amplitude_clusterized(spike_info)\n",
    "\n",
    "histogram_amplitude_clusterized(updated_spike_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
